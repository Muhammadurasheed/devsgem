"""
Google Cloud Service - Production-Grade Cloud Run Deployment
FAANG-level implementation with:
- Structured logging with correlation IDs
- Exponential retry with circuit breaker
- Metrics and monitoring hooks
- Security best practices
- Cost optimization
- Direct API usage (no CLI required)
"""

import os
import json
import base64
import tarfile
import io
from typing import Dict, List, Optional, Callable, Any
from pathlib import Path
import asyncio
import logging
import time
from datetime import datetime, timezone, timedelta
from enum import Enum
import subprocess

# Google Cloud API clients (no CLI required!)
from google.cloud.devtools import cloudbuild_v1
from google.cloud import run_v2
from google.cloud import logging as cloud_logging
from google.cloud import secretmanager
from google.cloud import monitoring_v3
from google.api_core import retry
from google.api_core import exceptions as google_exceptions
from google.protobuf import field_mask_pb2  # For update_mask in Cloud Run updates

# Configure structured logging
# Configure structured logging with safe filter
from utils.logging_utils import CorrelationIdFilter

# Use standard logging configuration (FastAPI/Uvicorn will handle setup)


class DeploymentStage(Enum):
    """Deployment stages for tracking"""
    INIT = "initialization"
    VALIDATE = "validation"
    BUILD = "build"
    PUSH = "push"
    DEPLOY = "deploy"
    VERIFY = "verification"
    COMPLETE = "complete"


class RetryStrategy:
    """Exponential backoff retry with jitter"""
    
    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
    
    async def execute(self, func, *args, **kwargs):
        """Execute function with exponential backoff"""
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                last_exception = e
                if attempt < self.max_retries - 1:
                    delay = self.base_delay * (2 ** attempt)
                    logging.warning(f"Retry attempt {attempt + 1}/{self.max_retries} after {delay}s: {e}")
                    await asyncio.sleep(delay)
        
        raise last_exception


class GCloudService:
    """
    FAANG-Level Google Cloud Platform Integration
    
    Features:
    - Structured logging with correlation IDs
    - Retry logic with exponential backoff
    - Metrics collection and monitoring
    - Security best practices (least privilege)
    - Cost optimization (resource allocation)
    - Health checks and rollback support
    """
    
    def __init__(
        self, 
        project_id: Optional[str] = None, 
        region: str = 'us-central1',
        correlation_id: Optional[str] = None
    ):
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT')
        self.region = region or os.getenv('GOOGLE_CLOUD_REGION', 'us-central1')
        self.artifact_registry = f'{self.region}-docker.pkg.dev'
        self.correlation_id = correlation_id or self._generate_correlation_id()
        self.retry_strategy = RetryStrategy(max_retries=1)
        self.metrics = {
            'builds': {'total': 0, 'success': 0, 'failed': 0},
            'deployments': {'total': 0, 'success': 0, 'failed': 0},
            'build_times': [],
            'deploy_times': []
        }
        
        if not self.project_id:
            print("[GCloudService]  WARNING: No project_id provided or found in environment. Defaulting to 'devgem-i4i' for safety.")
            self.project_id = "devgem-i4i"
        
        print(f"[DEBUG] GCloudService self.project_id: '{self.project_id}' (Type: {type(self.project_id)})")
            
        # Initialize Google Cloud API clients (no CLI required!)
        #  FAANG FIX: Explicitly pass project context where supported to prevent desync
        # NOTE: client_options with quota_project_id is a robust way to ensure project isolation
        from google.api_core.client_options import ClientOptions
        client_options = ClientOptions(quota_project_id=self.project_id)
        
        self.build_client = cloudbuild_v1.CloudBuildClient(client_options=client_options)
        self.run_client = run_v2.ServicesClient(client_options=client_options)
        self.logging_client = cloud_logging.Client(project=self.project_id)
        self.secret_manager_client = secretmanager.SecretManagerServiceClient(client_options=client_options)
        self.monitoring_client = monitoring_v3.MetricServiceClient(client_options=client_options)
        
        # Configure logger with correlation ID
        self.logger = logging.LoggerAdapter(
            logging.getLogger(__name__),
            {'correlation_id': self.correlation_id}
        )
        
        if not self.project_id:
            raise ValueError('GOOGLE_CLOUD_PROJECT environment variable required')
        
        self.logger.info(f"Initialized GCloudService for project: {self.project_id}")
        self.logger.info("[SUCCESS] Using Google Cloud APIs directly (no CLI required)")
    
    def _generate_correlation_id(self) -> str:
        """Generate unique correlation ID for request tracking"""
        import uuid
        return f"gcp-{uuid.uuid4().hex[:12]}"
    
    def validate_gcloud_auth(self) -> Dict:
        """
        DevGem ARCHITECTURE: We use DevGem's service account for all deployments.
        Users don't need their own GCP accounts. This method now always returns authenticated=True
        since we're using DevGem's managed infrastructure.
        """
        # DevGem uses its own service account - no user authentication needed
        return {
            'authenticated': True,
            'account': 'servergem-platform@servergem.iam.gserviceaccount.com',
            'project': self.project_id,
            'note': 'Using DevGem managed infrastructure'
        }
    
    def _create_source_tarball(self, project_path: str) -> bytes:
        """Create tarball of project source code for Cloud Build"""
        tar_stream = io.BytesIO()
        
        with tarfile.open(fileobj=tar_stream, mode='w:gz') as tar:
            project_path_obj = Path(project_path)
            
            for file_path in project_path_obj.rglob('*'):
                if file_path.is_file():
                    # Skip common ignore patterns
                    relative_path = file_path.relative_to(project_path_obj)
                    
                    skip_patterns = ['.git', '__pycache__', 'node_modules', '.env', '.venv', 'venv']
                    if any(pattern in str(relative_path) for pattern in skip_patterns):
                        continue
                    
                    tar.add(file_path, arcname=str(relative_path))
        
        tar_stream.seek(0)
        return tar_stream.read()
            
    def _create_tarball_dockerfile_only(self, project_path: str) -> bytes:
        """Create tarball containing ONLY Dockerfile and .dockerignore"""
        tar_stream = io.BytesIO()
        
        with tarfile.open(fileobj=tar_stream, mode='w:gz') as tar:
            project_path_obj = Path(project_path)
            
            for filename in ['Dockerfile', '.dockerignore']:
                file_path = project_path_obj / filename
                if file_path.exists():
                    tar.add(file_path, arcname=filename)
        
        tar_stream.seek(0)
        return tar_stream.read()
    
    
    async def preflight_checks(self, progress_notifier=None, progress_callback=None, abort_event: Optional[asyncio.Event] = None) -> Dict:
        """
        PHASE 3: Pre-flight GCP environment checks
        Verifies all required APIs and resources before deployment
        """
        if abort_event and abort_event.is_set():
            return {'success': False, 'error': 'Aborted'}
        checks = {
            'project_access': False,
            'artifact_registry': False,
            'cloud_build_api': False,
            'cloud_run_api': False,
            'storage_bucket': False
        }
        errors = []
        
        try:
            # PHASE 1.1: Pre-flight checks stage
            if progress_notifier:
                await progress_notifier.start_stage(
                    "repo_access",
                    "[INFO] Running GCP environment checks..."
                )
            
            # Check 1: Project access
            try:
                from google.cloud import resourcemanager_v3
                client = resourcemanager_v3.ProjectsClient()
                project_name = f"projects/{self.project_id}"
                project = await asyncio.to_thread(client.get_project, name=project_name)
                checks['project_access'] = True
                if progress_notifier:
                    await progress_notifier.update_progress(
                        "repo_access",
                        f"[SUCCESS] Project access verified: {self.project_id}",
                        15
                    )
            except Exception as e:
                errors.append(f"Project access failed: {str(e)}")
                if progress_notifier:
                    await progress_notifier.fail_stage(
                        "repo_access",
                        f"[ERROR] Project access check failed: {str(e)}"
                    )
            
            # Check 2: Artifact Registry repository exists (auto-create if missing)
            try:
                # CRITICAL: Correct import path for Artifact Registry
                from google.cloud import artifactregistry_v1
                ar_client = artifactregistry_v1.ArtifactRegistryClient()
                repo_name = f"projects/{self.project_id}/locations/{self.region}/repositories/servergem"
                
                try:
                    repository = await asyncio.to_thread(ar_client.get_repository, name=repo_name)
                    checks['artifact_registry'] = True
                    if progress_notifier:
                        await progress_notifier.update_progress(
                            "repo_access",
                            "[SUCCESS] Artifact Registry verified",
                            25
                        )
                except google_exceptions.NotFound:
                    # PHASE 3: Auto-create Artifact Registry
                    if progress_notifier:
                        await progress_notifier.update_progress(
                            "repo_access",
                            "[INFO] Creating Artifact Registry repository...",
                            20
                        )
                    
                    parent = f"projects/{self.project_id}/locations/{self.region}"
                    repository = artifactregistry_v1.Repository(
                        format_=artifactregistry_v1.Repository.Format.DOCKER,
                        description="DevGem deployments"
                    )
                    
                    operation = await asyncio.to_thread(
                        ar_client.create_repository,
                        parent=parent,
                        repository_id="servergem",
                        repository=repository
                    )
                    
                    # Wait for creation
                    await asyncio.to_thread(operation.result, timeout=60)
                    checks['artifact_registry'] = True
                    
                    if progress_notifier:
                        await progress_notifier.update_progress(
                            "repo_access",
                            "[SUCCESS] Artifact Registry created successfully",
                            30
                        )
                    
            except Exception as e:
                errors.append(f"Artifact Registry check failed: {str(e)}")
                if progress_notifier:
                    await progress_notifier.update_progress(
                        "repo_access",
                        f"[WARNING] Artifact Registry issue: {str(e)[:50]}",
                        25
                    )
            
            # Pre-flight checks complete
            if progress_notifier and all(checks.values()):
                await progress_notifier.complete_stage(
                    "repo_access",
                    "[SUCCESS] All GCP environment checks passed",
                    details={
                        'project': self.project_id,
                        'region': self.region,
                        'apis_enabled': sum(1 for v in checks.values() if v)
                    }
                )
            elif progress_notifier and errors:
                await progress_notifier.fail_stage(
                    "repo_access",
                    f"[ERROR] Pre-flight checks failed: {'; '.join(errors[:2])}",
                    details={'errors': errors}
                )
            try:
                # Try to list builds to verify API is enabled
                parent = f"projects/{self.project_id}/locations/{self.region}"
                request = cloudbuild_v1.ListBuildsRequest(
                    parent=parent,
                    page_size=1
                )
                await asyncio.to_thread(self.build_client.list_builds, request=request)
                checks['cloud_build_api'] = True
                if progress_callback:
                    await progress_callback("[SUCCESS] Cloud Build API enabled")
            except Exception as e:
                errors.append(f"Cloud Build API not enabled: {str(e)}")
                if progress_callback:
                    await progress_callback("[ERROR] Cloud Build API not enabled")
            
            # Check 4: Cloud Run API enabled
            try:
                parent = f"projects/{self.project_id}/locations/{self.region}"
                request = run_v2.ListServicesRequest(parent=parent, page_size=1)
                await asyncio.to_thread(self.run_client.list_services, request=request)
                checks['cloud_run_api'] = True
                if progress_callback:
                    await progress_callback("[SUCCESS] Cloud Run API enabled")
            except Exception as e:
                errors.append(f"Cloud Run API not enabled: {str(e)}")
                if progress_callback:
                    await progress_callback("[ERROR] Cloud Run API not enabled")
            
            # Check 5: Storage bucket exists (auto-create if missing)
            try:
                from google.cloud import storage
                storage_client = storage.Client(project=self.project_id)
                bucket_name = f'{self.project_id}_cloudbuild'
                
                try:
                    bucket = await asyncio.to_thread(storage_client.get_bucket, bucket_name)
                    checks['storage_bucket'] = True
                    if progress_callback:
                        await progress_callback("[SUCCESS] Cloud Build bucket found")
                except Exception:
                    # Auto-create bucket
                    if progress_callback:
                        await progress_callback("[INFO] Creating Cloud Build bucket...")
                    
                    bucket = await asyncio.to_thread(
                        storage_client.create_bucket,
                        bucket_name,
                        location=self.region
                    )
                    checks['storage_bucket'] = True
                    
                    if progress_callback:
                        await progress_callback("[SUCCESS] Cloud Build bucket created")
                        
            except Exception as e:
                errors.append(f"Storage bucket check failed: {str(e)}")
                if progress_callback:
                    await progress_callback("[ERROR] Storage bucket check failed")
            
            all_passed = all(checks.values())
            
            return {
                'success': all_passed,
                'checks': checks,
                'errors': errors,
                'message': '[SUCCESS] All pre-flight checks passed' if all_passed else '[ERROR] Some pre-flight checks failed'
            }
            
        except Exception as e:
            self.logger.error(f"Pre-flight checks failed: {e}")
            return {
                'success': False,
                'checks': checks,
                'errors': errors + [str(e)],
                'message': 'Pre-flight checks encountered an error'
            }
    
    async def build_image(
        self, 
        project_path: str, 
        image_name: str,
        progress_callback: Optional[Callable] = None,
        build_config: Optional[Dict] = None,
        repo_url: Optional[str] = None,
        github_token: Optional[str] = None,
        abort_event: Optional[asyncio.Event] = None # [FAANG]
    ) -> Dict:
        """
        PHASE 3: Build Docker image with retry logic and better error handling
        
        Features:
        - Pre-flight checks before building
        - Retry logic for transient failures
        - Multi-stage build support
        - Build cache optimization
        - Parallel layer builds
        - Build time metrics
        - Detailed error messages
        
        Args:
            project_path: Local path to project with Dockerfile
            image_name: Name for the image (e.g., 'my-app')
            progress_callback: Optional async callback for progress updates
            build_config: Optional build configuration (timeout, machine_type, etc.)
            repo_url: URL of the repository to clone (for Remote Build)
            github_token: OAuth token for private repository access
        """
        
        # PHASE 3: Wrap in retry strategy
        async def _build_with_retry():
            return await self._build_image_internal(
                project_path,
                image_name,
                progress_callback,
                build_config,
                repo_url,
                github_token,
                abort_event=abort_event # [FAANG]
            )
        
        try:
            return await _build_with_retry()
        except Exception as e:
            self.logger.error(f"Build failed: {e}")
            return {
                'success': False,
                'error': f'Build failed: {str(e)}\n\n' + 
                         'Common issues:\n' +
                         ' Check Dockerfile syntax\n' +
                         ' Ensure Cloud Build API is enabled\n' +
                         ' Verify billing is enabled\n' +
                         ' Check service account permissions'
            }
    
    async def _build_image_internal(
        self,
        project_path: str,
        image_name: str,
        progress_callback: Optional[Callable] = None,
        build_config: Optional[Dict] = None,
        repo_url: Optional[str] = None,
        github_token: Optional[str] = None,
        dockerfile_content: Optional[str] = None,
        abort_event: Optional[asyncio.Event] = None  # [FAANG]
    ) -> Dict:
        """Internal build implementation with detailed error handling"""
        start_time = time.time()
        self.metrics['builds']['total'] += 1
        
        try:
            print(f"[GCloudService] [INFO] Starting deployment flow for: {image_name}")
            project_path_obj = Path(project_path).resolve()
            
            #  Reset monotonic progress tracker for new build
            self._max_build_progress = 0
            
            self.logger.info(f"Starting Cloud Build API for: {image_name}")
            self.logger.info(f"Project path: {project_path_obj}")
            
            # Validate project path exists
            if not project_path_obj.exists():
                return {
                    'success': False,
                    'error': f"Project path not found: {project_path_obj}"
                }
            
            # Validate Dockerfile exists
            dockerfile_path = project_path_obj / 'Dockerfile'
            if not dockerfile_path.exists():
                return {
                    'success': False,
                    'error': f"Dockerfile not found in: {project_path_obj}"
                }
            
            print(f"[GCloudService] [SUCCESS] Dockerfile verified at: {dockerfile_path}")
            
            image_tag = f'{self.artifact_registry}/{self.project_id}/servergem/{image_name}:latest'
            
            if progress_callback:
                await progress_callback({
                    'stage': 'container_build',
                    'progress': 10,
                    'message': f'[INFO] Preparing source code for Cloud Build...',
                    'details': [f'Image: {image_tag}']
                })
            
            # PHASE 3 CRITICAL FIX: True Remote Build - NO LOCAL CLONE
            # Instead of uploading local tarball, Cloud Build clones directly from GitHub
            # This is the FAANG-level scalable approach
            
            # Initialize build configuration
            build = cloudbuild_v1.Build()
            build.source = cloudbuild_v1.Source()
            
            if repo_url:
                print(f"[GCloudService] [DEPLOY] TRUE REMOTE BUILD: Cloud Build will clone {repo_url} directly")
                
                if progress_callback:
                    await progress_callback({
                        'type': 'thought',
                        'content': f"Initiating high-speed remote build channel for {repo_url}...",
                    })
                    await progress_callback({
                        'type': 'thought',
                        'content': "Provisioning ephemeral build nodes for high-performance container synthesis..."
                    })
                    
                    await progress_callback({
                        'stage': 'container_build',
                        'progress': 15,
                        'message': 'Cloud Build is fetching code directly from GitHub...',
                    })
                
                # Prepare clone command with authentication if token provided
                clone_args = ['clone', '--depth', '1']
                
                if github_token:
                    # CRITICAL: Authenticate for private repo access
                    # Strip protocol to avoid double prefix
                    clean_repo = repo_url.split('github.com/')[-1]
                    auth_url = f"https://oauth2:{github_token}@github.com/{clean_repo}"
                    clone_args.extend([auth_url, '/workspace/repo'])
                    print(f"[GCloudService] [DEPLOY] Using authenticated clone for {clean_repo}")
                else:
                    clone_args.extend([repo_url, '/workspace/repo'])
                
                #  LANGUAGE-AWARE HEALING: Only upload files relevant to the detected language
                # This prevents NPM errors when deploying Python/Go projects
                language = (build_config.get('language', 'unknown') if build_config else 'unknown').lower()
                
                # Define language-specific files to heal
                # Define language-specific files to heal
                #  FIX: Exclude large lockfiles (package-lock.json, go.sum) which exceed Cloud Build API arg limits (10k chars)
                # We assume these exist in the remote repo. We primarily need to inject our optimized Dockerfile.
                language_files = {
                    'python': ['Dockerfile', '.dockerignore', 'requirements.txt', 'runtime.txt'],
                    'nodejs': ['Dockerfile', '.dockerignore', 'package.json', 'tsconfig.json'], # [FIX] Inject sanitized tsconfig
                    'node': ['Dockerfile', '.dockerignore', 'package.json', 'tsconfig.json'],   # [FIX] Inject sanitized tsconfig
                    'golang': ['Dockerfile', '.dockerignore', 'go.mod'],
                    'go': ['Dockerfile', '.dockerignore', 'go.mod'],
                }
                
                # Get files for this language, fallback to just Dockerfile if unknown
                files_to_heal = language_files.get(language, ['Dockerfile', '.dockerignore'])
                print(f"[GCloudService] [HEALING] Language: {language}, Primary files: {files_to_heal}")
                
                arch_files = {}
                for filename in files_to_heal:
                    file_path = project_path_obj / filename
                    if file_path.exists():
                        try:
                            with open(file_path, 'rb') as f:
                                arch_files[filename] = base64.b64encode(f.read().replace(b'\r\n', b'\n')).decode('utf-8')
                            print(f"[GCloudService] [HEALING] Injecting: {filename}")
                        except Exception as e:
                            print(f"[GCloudService] Warning: Could not read {filename} for healing: {e}")

                # TRUE REMOTE: Cloud Build steps that clone from GitHub
                # No local tarball upload - build happens entirely in cloud
                
                healing_steps = []
                for filename, b64_content in arch_files.items():
                    healing_steps.append(
                        cloudbuild_v1.BuildStep(
                            name='bash',
                            args=['-c', f'echo "{b64_content}" | base64 -d > /workspace/repo/{filename}'],
                        )
                    )

                build.steps = [
                    # Step 0: Clone directly from GitHub (NO LOCAL CLONE!)
                    cloudbuild_v1.BuildStep(
                        name='gcr.io/cloud-builders/git',
                        args=clone_args,
                        timeout={'seconds': 300}
                    ),
                    # Step 1+: Write our healed architecture files
                    *healing_steps,
                    # Step Last: Build from the cloned repo using Kaniko for elite caching
                    cloudbuild_v1.BuildStep(
                        name='gcr.io/kaniko-project/executor:latest',
                        args=[
                            '--dockerfile=Dockerfile',
                            '--context=dir:///workspace/repo',
                            f'--destination={image_tag}',
                            '--cache=false', # FINAL STAND: Disable cache to ensure entrypoint integrity
                        ],
                        timeout={'seconds': 1200}
                    )
                ]
                
                # For TRUE REMOTE, we use a minimal tarball (just a placeholder)
                # Cloud Build requires SOME source, but we don't upload the actual code
                minimal_tar = io.BytesIO()
                with tarfile.open(fileobj=minimal_tar, mode='w:gz') as tar:
                    # Add a dummy file so Cloud Build accepts the source
                    dummy_content = b"# Cloud Build source - actual code cloned from GitHub"
                    dummy_info = tarfile.TarInfo(name="README.md")
                    dummy_info.size = len(dummy_content)
                    tar.addfile(dummy_info, io.BytesIO(dummy_content))
                minimal_tar.seek(0)
                source_bytes = minimal_tar.read()
                
            else:
                print(f"[GCloudService] [DEPLOY] Using Local Source Strategy (Legacy - no repo_url provided)")
                
                # Create full source tarball for local-only builds
                source_bytes = await asyncio.to_thread(
                    self._create_source_tarball, 
                    str(project_path_obj)
                )
                
                build.steps = [
                    cloudbuild_v1.BuildStep(
                        name='gcr.io/kaniko-project/executor:latest',
                        args=[
                            '--dockerfile=Dockerfile',
                            '--context=dir:///workspace',
                            f'--destination={image_tag}',
                            '--cache=false',
                        ],
                        timeout={'seconds': 1200}
                    )
                ]
            
            # IMPORTANT: When using Kaniko (--destination set), do NOT use build.images.
            # Kaniko pushes directly to the registry. Cloud Build's images block tries to 
            # verify/push from the local daemon, which fails with Kaniko.
            # build.images = [image_tag] 
            
            # Set machine type and timeout
            build.options = cloudbuild_v1.BuildOptions(
                machine_type=cloudbuild_v1.BuildOptions.MachineType.E2_HIGHCPU_8,
                logging=cloudbuild_v1.BuildOptions.LoggingMode.GCS_ONLY,
            )
            # overall timeout must be >= any step timeout (Kaniko is 1200s)
            build.timeout = {'seconds': 1800} # 30 minutes
            
            # CRITICAL FIX: Upload source to GCS bucket first
            # Create/ensure bucket exists
            bucket_name = f'{self.project_id}_cloudbuild'
            
            try:
                from google.cloud import storage
                storage_client = storage.Client(project=self.project_id)
                
                # Get or create bucket
                try:
                    bucket = storage_client.get_bucket(bucket_name)
                    self.logger.info(f"[SUCCESS] Using existing bucket: {bucket_name}")
                except Exception:
                    # Create bucket if it doesn't exist
                    self.logger.info(f"Creating Cloud Build bucket: {bucket_name}")
                    bucket = storage_client.create_bucket(
                        bucket_name, 
                        location=self.region
                    )
                    self.logger.info(f"[SUCCESS] Created bucket: {bucket_name}")
                
                # Upload source tarball
                blob_name = f'source-{int(time.time())}.tar.gz'
                blob = bucket.blob(blob_name)
                
                self.logger.info(f"Uploading source to gs://{bucket_name}/{blob_name}...")
                await asyncio.to_thread(
                    blob.upload_from_string,
                    source_bytes,
                    content_type='application/gzip'
                )
                self.logger.info(f"[SUCCESS] Source uploaded successfully")
                
                # Reference the uploaded source
                build.source.storage_source = cloudbuild_v1.StorageSource(
                    bucket=bucket_name,
                    object_=blob_name
                )
                
            except Exception as upload_error:
                self.logger.error(f"Failed to upload source: {upload_error}")
                return {
                    'success': False,
                    'error': f'Failed to upload source to Cloud Storage: {str(upload_error)}'
                }
            
            if progress_callback:
                await progress_callback({
                    'stage': 'container_build',
                    'progress': 30,
                    'message': 'Starting Cloud Build (this may take a few minutes)...',
                })
            
            # Submit build
            parent = f"projects/{self.project_id}/locations/{self.region}"
            
            # [FIXED] Removed extremely verbose prints of 'build' object which cause Errno 22 on Windows consoles
            print(f"[GCloudService] [INFO] Sending build request to Google Cloud Build (Project: {self.project_id})...", flush=True)
            
            # [SUCCESS] API FIX: Clear read-only fields that cause 400 Violation Errors
            if hasattr(build, 'substitutions'):
                if hasattr(build.substitutions, 'clear'):
                    build.substitutions.clear()
                else:
                    try:
                        build.substitutions = {}
                    except:
                        pass

            try:
                operation = await asyncio.to_thread(
                    self.build_client.create_build,
                    project_id=self.project_id,
                    build=build
                )
            except Exception as e:
                print(f"[GCloudService] [CRITICAL] [ERROR] Cloud Build API Error: {e}", flush=True)
                import traceback
                traceback.print_exc()
                return {
                    'success': False,
                    'error': f"Failed to initiate build: {str(e)}"
                }
            
            build_id = operation.metadata.build.id
            print(f"[GCloudService] [SUCCESS] Cloud Build ID: {build_id}", flush=True)
            self.logger.info(f"Cloud Build started: {build_id}")
            
            # ENHANCED: Poll with REAL Cloud Build status updates
            progress = 30
            poll_count = 0
            log_offset = 0
            logs_bucket = build.logs_bucket or f"{self.project_id}_cloudbuild"

            # ENHANCED: Poll with REAL Cloud Build status updates
            while True:
                # [FAANG] Emergency Abort Check - High-Frequency Responsiveness
                if abort_event:
                    try:
                        # Wait for abort signal OR poll interval (3s), whichever is first
                        await asyncio.wait_for(abort_event.wait(), timeout=3.0)
                        # If reached here, abort_event was SET!
                        self.logger.warning(f"[FAANG] üõë Instant Abort received for build {build_id}.")
                        return {
                            'success': False,
                            'error': 'Deployment aborted by user.',
                            'code': 'ABORTED',
                            'aborted': True
                        }
                    except asyncio.TimeoutError:
                        # Continue to poll
                        pass
                else:
                    await asyncio.sleep(1)
                poll_count += 1

                # [FAANG TELEMETRY] Stream real-time logs from GCS
                if logs_bucket:
                    log_offset = await self._poll_build_logs(
                        build_id, 
                        logs_bucket, 
                        progress_callback, 
                        log_offset,
                        abort_event=abort_event # [FAANG]
                    )
                
                # REFRESH FROM GCP: Don't rely on stagnant operation object
                try:
                    current_build = await asyncio.to_thread(
                        self.build_client.get_build,
                        project_id=self.project_id,
                        id=build_id
                    )
                except Exception as e:
                    self.logger.warning(f"Could not refresh build status for {build_id}: {e}")
                    continue
                
                # Check status
                status = current_build.status
                self.logger.debug(f"Build {build_id} status: {status.name}")
                
                if status in [
                    cloudbuild_v1.Build.Status.SUCCESS,
                    cloudbuild_v1.Build.Status.FAILURE,
                    cloudbuild_v1.Build.Status.INTERNAL_ERROR,
                    cloudbuild_v1.Build.Status.TIMEOUT,
                    cloudbuild_v1.Build.Status.CANCELLED,
                    cloudbuild_v1.Build.Status.EXPIRED
                ]:
                    break
                
                # GRANULAR STEP-BASED PROGRESS WITH MONOTONIC GUARANTEE
                active_msg = "Processing build..."
                step_details = []
                
                if current_build.steps:
                    completed_steps = sum(1 for s in current_build.steps if s.status == cloudbuild_v1.Build.Status.SUCCESS)
                    working_step = next((s for s in current_build.steps if s.status == cloudbuild_v1.Build.Status.WORKING), None)
                    total_steps = len(current_build.steps)
                    
                    # Construct detailed step log
                    for s in current_build.steps:
                        s_name = s.name.split('/')[-1]
                        s_status = s.status.name
                        icon = ""
                        if s_status == "SUCCESS": icon = ""
                        elif s_status == "WORKING": icon = ""
                        elif s_status == "FAILURE": icon = ""
                        elif s_status == "QUEUED": icon = "zzz"
                        
                        step_details.append(f"{icon} {s_name}: {s_status}")

                    # [FAANG BOOSTER] LINEAR PROGRESS ENGINE
                    # We calculate a "base progress" from completed steps, and adding a 
                    # "virtual booster" that smoothly fills the gap to the next step.
                    base_step_progress = (completed_steps / total_steps * 100) if total_steps > 0 else 5
                    
                    # Calculate how many "sub-ticks" we should add based on time spent in this step
                    # Kaniko (Build) usually takes 60-180s. We want to move ~1% every 2-3s.
                    # We use a logarithmic-ish slowdown as we approach the next big step jump.
                    
                    if not hasattr(self, '_current_step_start_time'):
                        self._current_step_start_time = time.time()
                        self._last_completed_count = completed_steps
                    
                    if completed_steps > self._last_completed_count:
                        # Reset booster for new step
                        self._current_step_start_time = time.time()
                        self._last_completed_count = completed_steps
                        
                    time_in_step = time.time() - self._current_step_start_time
                    
                    # Booster speed: 0.8% every poll (4s) -> ~0.2% per second
                    # This ensures the UI feels "alive" even when GCP is silent.
                    virtual_booster = min(time_in_step * 0.25, (100 / total_steps) * 0.8) if total_steps > 0 else 2
                    
                    progress = base_step_progress + virtual_booster
                    
                    # Ensure we never exceed 99% until SUCCESS
                    progress = min(progress, 99)
                    
                    # Guaranteed Monotonic: Never go backwards
                    if not hasattr(self, '_prev_reported_progress'):
                        self._prev_reported_progress = 0
                    
                    progress = max(progress, self._prev_reported_progress + 0.1)
                    self._prev_reported_progress = progress
                    
                    if working_step:
                        step_name = working_step.name.split('/')[-1]
                        if 'git' in step_name: active_msg = "Cloning repository (GitHub connectivity)..."
                        elif 'bash' in step_name: active_msg = "Preparing container filesystem..."
                        elif 'kaniko' in step_name or 'executor' in step_name: active_msg = "Building & Layering image (This takes time)..."
                        else: active_msg = f"Executing: {step_name}..."
                else:
                    if status == cloudbuild_v1.Build.Status.QUEUED:
                        progress = 5
                        active_msg = "Cloud Build is QUEUED (Waiting for GCP resources)..."
                    else:
                        progress = 10
                        active_msg = "Provisioning specialized builder..."
                
                if progress_callback:
                    # [FAANG] Emergency Abort Check
                    if abort_event and abort_event.is_set():
                        print(f"[GCloudService] üõë Build ABORTED during polling loop")
                        return {'success': False, 'error': 'Aborted'}

                    await progress_callback({
                        'stage': 'container_build',
                        'status': 'in-progress', # [FIX] Explicit status
                        'progress': round(progress),
                        'message': f"{active_msg} ({round(progress)}%)",
                        'details': step_details if step_details else [f'Reference: {build_id}', f'Status: {status.name}']
                    })
                    await asyncio.sleep(0)
            
            # Check final result
            build_result = await asyncio.to_thread(
                self.build_client.get_build,
                project_id=self.project_id,
                id=build_id
            )
            
            build_duration = time.time() - start_time
            self.metrics['build_times'].append(build_duration)

            if build_result.status == cloudbuild_v1.Build.Status.SUCCESS:
                # [SOVEREIGN FIX] Fetch full build logs even on success
                self.logger.info(f"[GCloudService] Build {build_id} succeeded. Fetching logs...")
                log_excerpt = await self._fetch_build_logs(build_result, build_id)
                
                # [FAANG] Explicitly mark container_build as success immediately
                if progress_callback:
                    await progress_callback({
                        'stage': 'container_build',
                        'status': 'success',
                        'progress': 100,
                        'message': 'Container built successfully',
                        'details': log_excerpt.split('\n')[-200:] if log_excerpt else [f'Build ID: {build_id}', f'Duration: {build_duration:.1f}s']
                    })
            
            if build_result.status == cloudbuild_v1.Build.Status.SUCCESS:
                self.metrics['builds']['success'] += 1
                return {
                    'success': True,
                    'image_tag': image_tag,
                    'build_id': build_id,
                    'log_excerpt': log_excerpt
                }
            
            self.metrics['builds']['failed'] += 1
            
            #  FAANG-Level Error Diagnostics: Surface step-by-step logs
            error_details = []
            failed_step_log = None
            failed_step_index = -1
            
            if hasattr(build_result, 'steps') and build_result.steps:
                for i, step in enumerate(build_result.steps):
                    step_name = step.name.split('/')[-1] if step.name else f"Step {i}"
                    step_status = step.status.name if hasattr(step.status, 'name') else str(step.status)
                    
                    if step_status in ['FAILURE', 'TIMEOUT', 'CANCELLED']:
                        failed_step_log = f"Step '{step_name}' failed ({step_status})"
                        failed_step_index = i
                        if hasattr(step, 'timing') and step.timing:
                            failed_step_log += f" after {step.timing}"
                        error_details.append(failed_step_log)
            
            #  CRITICAL: Fetch actual log content from GCS
            log_excerpt = await self._fetch_build_logs(build_result, build_id)
            logs_url = build_result.log_url if hasattr(build_result, 'log_url') else None
            
            #  Check for common failure patterns in logs
            build_status_name = build_result.status.name if hasattr(build_result.status, 'name') else str(build_result.status)
            
            # Parse log excerpt for known error patterns
            error_msg = ""
            if log_excerpt:
                log_lower = log_excerpt.lower()
                if 'npm err!' in log_lower or 'npm error' in log_lower:
                    error_msg = "NPM ERROR detected in build. Check dependencies and scripts."
                elif 'enoent' in log_lower:
                    error_msg = "FILE NOT FOUND during build. Check if all files exist."
                elif 'out of memory' in log_lower or 'javascript heap' in log_lower:
                    error_msg = "OUT OF MEMORY during build. Project may need optimization."
                elif 'permission denied' in log_lower:
                    error_msg = "PERMISSION DENIED during build. Check file permissions."
                elif 'module not found' in log_lower or "cannot find module" in log_lower:
                    error_msg = "MODULE NOT FOUND. A required dependency is missing."
                elif 'no such file or directory' in log_lower:
                    if '/dist' in log_lower or '/build' in log_lower:
                        error_msg = "BUILD OUTPUT DIRECTORY NOT FOUND. The 'npm run build' may have failed or outputted to a different directory."
                
                # [FAANG BOOSTER] Google Principal Level Diagnostics
                elif 'error ts' in log_lower or 'typescript' in log_lower:
                    if 'ts6133' in log_lower:
                        error_msg = "TypeScript Error (TS6133): Unused variable detected. This is failing your build due to strict mode. Remove the unused variable or prefix with '_'."
                    elif 'ts6192' in log_lower:
                        error_msg = "TypeScript Error (TS6192): All imports in this block are unused. Clean up your imports to fix the build."
                    elif 'ts1484' in log_lower:
                        error_msg = "TypeScript Error (TS1484): Circular dependency or configuration conflict detected. Check your tsconfig.json."
                    else:
                        # Extract first TS error for the user
                        ts_match = re.search(r'error ts\d+: .+', log_excerpt, re.IGNORECASE)
                        error_msg = f"TypeScript Compilation Failed: {ts_match.group(0) if ts_match else 'Check logs for TS errors.'}"
                
                elif 'sh: 1: vite: not found' in log_lower or 'sh: 1: next: not found' in log_lower:
                    error_msg = "BUILD TOOL NOT FOUND. Ensure devDependencies are installed and the build command is correct."
            
            if not error_msg:
                if build_status_name == 'TIMEOUT':
                    error_msg = "Build TIMEOUT: The build took longer than the 30-minute limit."
                elif build_status_name == 'FAILURE':
                    if failed_step_index == 3:  # Kaniko step
                        error_msg = "Docker build failed. Check if package.json 'build' script works and outputs to 'dist' folder."
                    elif failed_step_log:
                        error_msg = f"Build FAILED: {failed_step_log}"
                    else:
                        error_msg = "Build FAILED during container construction."
                else:
                    error_msg = f"Build ended with status: {build_status_name}"
            
            # Construct user-friendly error message with log excerpt
            full_error = f"Error: {error_msg}\n\nBuild ID: {build_id}"
            if error_details:
                full_error += f"\n\nFailed Step: {'; '.join(error_details)}"
            if log_excerpt:
                #  Show last 50 lines in the UI (increased from 15)
                excerpt_lines = log_excerpt.split('\n')[-50:]
                full_error += f"\n\nLog Tail:\n```\n{chr(10).join(excerpt_lines)}\n```"
            if logs_url:
                full_error += f"\n\nFull Logs: {logs_url}"
            
            self.logger.error(f"Build failure details: {full_error[:500]}")
            
            return {
                'success': False,
                'error': full_error,
                'build_id': build_id,
                'status': build_status_name,
                'log_excerpt': log_excerpt[:2000] if log_excerpt else None
            }

        except Exception as e:
            self.metrics['builds']['failed'] += 1
            self.logger.error(f"Build exception: {str(e)}")
            return {
                'success': False,
                'error': f'Build failed: {str(e)}'
            }
    
    # ============================================================================
    # SECRET MANAGER INTEGRATION (FAANG-Level Security)
    # ============================================================================


    async def _fetch_build_logs(self, build_result, build_id: str) -> str:
        """
        [SOVEREIGN] Robust GCS Build Log Fetcher
        Fetches build logs from GCS with exponential retry and thread safety.
        """
        log_excerpt = ""
        gcs_log_url = None
        
        if hasattr(build_result, 'logs_bucket') and build_result.logs_bucket:
            bucket_name = build_result.logs_bucket
            if bucket_name.startswith('gs://'):
                bucket_name = bucket_name[5:]
            gcs_log_url = f"gs://{bucket_name}/log-{build_id}.txt"
        
        if not gcs_log_url:
            return ""

        try:
            self.logger.info(f"[GCloudService] üîç Fetching build logs from: {gcs_log_url}")
            
            def fetch_gcs_raw():
                from google.cloud import storage
                storage_client = storage.Client(project=self.project_id)
                
                parts = gcs_log_url[5:].split('/', 1)
                if len(parts) == 2:
                    bucket_name, blob_name = parts
                    bucket = storage_client.bucket(bucket_name)
                    blob = bucket.blob(blob_name)
                    
                    if blob.exists():
                        content = blob.download_as_text()
                        lines = content.strip().split('\n')
                        # [FAANG] Limit to last 1000 lines for high-fidelity debugging
                        # but don't overwhelm the frontend
                        last_lines = lines[-500:] if len(lines) > 500 else lines
                        return '\n'.join(last_lines)
                return ""

            log_excerpt = await asyncio.to_thread(fetch_gcs_raw)
            
            if log_excerpt:
                self.logger.info(f"[GCloudService] ‚úÖ Successfully fetched {len(log_excerpt.split('\n'))} log lines.")
                # Log a few lines to terminal for visibility
                tail_lines = log_excerpt.split('\n')[-5:]
                for line in tail_lines:
                    self.logger.info(f"[BUILD-TAIL] {line}")
            
            return log_excerpt
        except Exception as e:
            self.logger.warning(f"[GCloudService] ‚ö†Ô∏è Failed to fetch build logs from {gcs_log_url}: {e}")
            return ""

    async def create_or_update_secret(self, secret_id: str, payload: str) -> bool:
        """
        Create or update a secret in Google Secret Manager.
        
        Args:
            secret_id: The ID of the secret (e.g., 'devgem-repo-env')
            payload: The content to store
            
        Returns:
            bool: True if successful
        """
        try:
            client = self.secret_manager_client
            parent = f"projects/{self.project_id}"
            
            print(f"[SecretManager]  Attempting create/update in project: {self.project_id} (Internal ID: {secret_id})")
            
            # Create secret if it doesn't exist
            try:
                await asyncio.to_thread(
                    client.create_secret,
                    request={
                        "parent": parent,
                        "secret_id": secret_id,
                        "secret": {"replication": {"automatic": {}}},
                    }
                )
                self.logger.info(f"[SecretManager] Created new secret: {secret_id}")
            except google_exceptions.AlreadyExists:
                # self.logger.info(f"[SecretManager] Secret already exists: {secret_id}")
                pass
            except Exception as e:
                self.logger.error(f"[SecretManager] Error creating secret: {e}")
                return False

            # Add secret version
            parent_secret = f"{parent}/secrets/{secret_id}"
            # Ensure payload is robust string
            if not isinstance(payload, str):
                payload = json.dumps(payload)
                
            payload_bytes = payload.encode("UTF-8")
            
            await asyncio.to_thread(
                client.add_secret_version,
                request={
                    "parent": parent_secret,
                    "payload": {"data": payload_bytes},
                }
            )
            self.logger.info(f"[SecretManager] Added new version to secret: {secret_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"[SecretManager] Critical failure in Secret Manager: {e}")
            return False

    async def access_secret(self, secret_id: str) -> Optional[str]:
        """
        Access the latest version of a secret from Secret Manager.
        
        Returns:
            str: The payload content (usually JSON string), or None if failed
        """
        try:
            client = self.secret_manager_client
            name = f"projects/{self.project_id}/secrets/{secret_id}/versions/latest"
            
            print(f"[SecretManager]  Looking for secret: {name} in project: {self.project_id}")
            
            response = await asyncio.to_thread(
                client.access_secret_version, 
                request={"name": name}
            )
            payload = response.payload.data.decode("UTF-8")
            return payload
            
        except google_exceptions.NotFound:
            self.logger.warning(f"[SecretManager] Secret not found: {secret_id}")
            return None
        except Exception as e:
            self.logger.error(f"[SecretManager] Error accessing secret: {e}")
            return None

    async def deploy_to_cloudrun(
        self,
        image_tag: str,
        service_name: str,
        env_vars: Optional[Dict[str, str]] = None,
        secrets: Optional[Dict[str, str]] = None,
        progress_callback: Optional[Callable] = None,
        user_id: Optional[str] = None,
        health_check_path: str = '/',
        memory_limit: str = '512Mi',
        cpu_limit: str = '1',
        abort_event: Optional[asyncio.Event] = None,  # [FAANG]
        container_port: Optional[int] = None,
        on_url_ready: Optional[Callable] = None # [FAANG] Snapshot reveal hook
    ) -> Dict:
        """
        Deploy image to Cloud Run using API (no CLI required!)
        
        Args:
            image_tag: Full image tag from Artifact Registry
            service_name: Cloud Run service name (will be prefixed with user_id)
            env_vars: Environment variables dict
            secrets: Secrets to mount (name: secret_path)
            progress_callback: Optional async callback for progress updates
            user_id: User identifier for service isolation
        """
        try:
            progress = 0 # Initialize scope safety
            # Generate unique service name for user isolation
            prefix = f"{user_id}-" if user_id else ""
            remaining_len = 48 - len(prefix) # Ensure total < 50
            
            clean_service_name = service_name.lower().replace('_', '-')
            truncated_name = clean_service_name[:remaining_len].strip('-')
            
            unique_service_name = f"{prefix}{truncated_name}"
            
            self.logger.info(f"Deploying service: {unique_service_name}")
            
            if progress_callback:
                await progress_callback({
                    'stage': 'cloud_deployment',
                    'progress': 10,
                    'message': f'[DEPLOY] Deploying {unique_service_name} to Cloud Run...'
                })
            
            # Build parent path
            parent = f"projects/{self.project_id}/locations/{self.region}"
            service_path = f"{parent}/services/{unique_service_name}"
            
            # Create service configuration
            service = run_v2.Service()
            service.name = service_path
            
            # Configure template
            service.template = run_v2.RevisionTemplate()
            
            # Container configuration
            container = run_v2.Container()
            container.image = image_tag
            
            # Use name 'main' for the container
            container.name = "main"
            
            # CRITICAL FIX: Dynamic port detection (explicit, env_vars PORT, or default 8080)
            detected_port = container_port or 8080
            if env_vars and 'PORT' in env_vars:
                try:
                    detected_port = int(env_vars['PORT'])
                    self.logger.info(f"[Diagnostic] PORT found in env_vars: {detected_port}")
                except (ValueError, TypeError):
                    self.logger.warning(f"Invalid PORT in env_vars, using {detected_port}")
            
            self.logger.info(f"Using container port: {detected_port}")
            container.ports = [run_v2.ContainerPort(container_port=detected_port, name='http1')]
            
            # Add environment variables
            if env_vars:
                self.logger.info(f"[DEBUG] Adding {len(env_vars)} env vars to container: {list(env_vars.keys())}")
                #  CRITICAL FIX: Filter out PORT (Reserved by Cloud Run)
                container.env = [
                    run_v2.EnvVar(name=str(k), value=str(v))
                    for k, v in env_vars.items()
                    if k != 'PORT' 
                ]
                self.logger.info(f"[DEBUG] Container env set with {len(container.env)} variables")
            else:
                self.logger.warning("[DEBUG] No env_vars provided to deploy_to_cloudrun")
            
            # Resource limits
            container.resources = run_v2.ResourceRequirements(
                limits={'cpu': str(cpu_limit), 'memory': str(memory_limit)}
            )
            
            # Startup probe - CRITICAL FIX: Switched to TCP Socket (Universal Framework Support)
            # TCP probes verify the container is listening on the port, regardless of internal routing/prefixes.
            # This fixes the "404 Not Found" issue for prefixed APIs (like NestJS) that don't serve "/" but are listening.
            self.logger.info(f"Setting startup probe to: TCP port {detected_port}")
            container.startup_probe = run_v2.Probe(
                tcp_socket=run_v2.TCPSocketAction(port=detected_port),
                initial_delay_seconds=0,
                timeout_seconds=5,
                period_seconds=2,
                failure_threshold=90 # 90 * 2s = 180s max startup time
            )
            
            # Liveness probe - REMOVED due to Cloud Run limitation
            # Cloud Run does not support TCP for Liveness (only Startup).
            # Since we cannot guess the user's HTTP paths (/, /health, etc),
            # we rely on the TCP Startup Probe (above) to verify the app is listening.
            # Process health is managed by the platform (restarts on crash).
            # container.liveness_probe = None
            
            service.template.containers = [container]
            
            # Scaling configuration
            service.template.scaling = run_v2.RevisionScaling(
                min_instance_count=0,
                max_instance_count=10
            )
            
            # Timeout
            service.template.timeout = {'seconds': 300}
            
            # Labels
            service.labels = {
                'managed-by': 'servergem',
                'user-id': user_id or 'unknown'
            }
            
            if progress_callback:
                await progress_callback({
                    'type': 'thought',
                    'content': "Synthesizing Cloud Run manifest... calibrating serverless container parameters."
                })
                await progress_callback({
                    'type': 'thought',
                    'content': f"Configuring global ingress via Google Front End (GFE)... targeting {self.region}."
                })
                await progress_callback({
                    'type': 'thought',
                    'content': "Enabling Secret Manager parity for secure environment variable injection."
                })
                await progress_callback({
                    'type': 'thought',
                    'content': f"Mapping TCP Startup Probe to port {detected_port} for high-fidelity health monitoring."
                })
                await progress_callback({
                    'stage': 'cloud_deployment',
                    'progress': 30,
                    'message': 'Creating Cloud Run service...'
                })
            
            # Check if service exists
            try:
                existing_service = await asyncio.to_thread(
                    self.run_client.get_service,
                    name=service_path
                )
                
                # Service exists, update it
                self.logger.info(f"Updating existing service: {unique_service_name}")
                
                # CRITICAL FIX: Must specify update_mask to ensure env vars are applied!
                # Without update_mask, Cloud Run API may NOT update container environment variables.
                # We update the entire template to ensure all changes are applied.
                update_mask = field_mask_pb2.FieldMask(paths=[
                    'template.containers',  # This includes image, env vars, resources, probes
                    'template.scaling',
                    'template.timeout',
                    'labels'
                ])
                
                self.logger.info(f"[DEBUG] Using update_mask: {update_mask.paths}")
                
                operation = await asyncio.to_thread(
                    self.run_client.update_service,
                    service=service,
                    update_mask=update_mask
                )
                
            except google_exceptions.NotFound:
                # Service doesn't exist, create it
                self.logger.info(f"Creating new service: {unique_service_name}")
                
                # CRITICAL: For CreateService, the service.name MUST be empty in the request body
                # because it is specified via service_id/parent.
                service_for_create = run_v2.Service(service)
                service_for_create.name = "" # Force empty as per API contract
                
                operation = await asyncio.to_thread(
                    self.run_client.create_service,
                    parent=parent,
                    service=service_for_create,
                    service_id=unique_service_name
                )
            
            # 4. ROBUST POLLING with detailed feedback
            self.logger.info(f"Deployment operation started: {operation.operation.name}")
            
            # Base progress for deployment starts at 86% (after image build)
            base_progress = 86
            poll_count = 0
            
            while True:
                poll_count += 1
                if progress_callback:
                    if poll_count == 2:
                        await progress_callback({'type': 'thought', 'content': "Watching Cloud Run revision status... container is cold-starting via Artifact Registry."})
                        await progress_callback({'type': 'thought', 'content': "Allocating compute resources... initializing global VPC connector."})
                    elif poll_count == 5:
                        await progress_callback({'type': 'thought', 'content': "Routing traffic to new revision... verifying TCP liveness probes."})
                        await progress_callback({'type': 'thought', 'content': "Finalizing high-availability network topology for global scale."})
                
                # [FAANG] Emergency Abort Check - High-Frequency Responsiveness
                if abort_event:
                    try:
                        # Wait for abort signal OR poll interval (4s), whichever is first
                        await asyncio.wait_for(abort_event.wait(), timeout=4.0)
                        # If reached here, abort_event was SET!
                        self.logger.warning(f"[FAANG] üõë Instant Abort received for Cloud Run deployment.")
                        return {
                            'success': False,
                            'error': 'Deployment aborted by user.',
                            'code': 'ABORTED',
                            'aborted': True
                        }
                    except asyncio.TimeoutError:
                        # Continue to poll
                        pass
                else:
                    await asyncio.sleep(4)
                
                # REFRESH status
                try:
                    current_service = await asyncio.to_thread(
                        self.run_client.get_service,
                        name=service_path
                    )
                    
                    # Calculate fluid progress (86 to 98)
                    fluid_increment = min(poll_count * 1.5, 12)
                    progress = min(base_progress + fluid_increment, 98)
                    
                    # Update status message with granular timing
                    status_msg = f"[DEPLOY] Provisioning container ({poll_count * 4}s)"
                    
                    # Check Service Status for terminal signals (Catch 400s early!)
                    if current_service and current_service.terminal_condition:
                        term = current_service.terminal_condition
                        if term.state.name == "CONDITION_FAILED":
                            error_reason = term.message or "Service provisioning failed"
                            self.logger.error(f"[FAILURE] Cloud Run reported terminal error: {error_reason}")
                            # Don't wait for operation timeout, raise now!
                            raise Exception(f"Cloud Run Deployment Failed: {error_reason}")
                    
                    if poll_count > 5: status_msg = "Synthesizing high-availability network topology..."
                    if poll_count > 10: status_msg = "Calibrating global container instances (Warm-up phase)..."
                    if poll_count > 15: status_msg = "Finalizing secure traffic migration (Zero-downtime)..."
                    
                    if progress_callback:
                        latest_rev = current_service.latest_ready_revision.split('/')[-1] if current_service.latest_ready_revision else 'Provisioning...'
                        
                        # Gather conditions for detailed status
                        conditions_log = []
                        if current_service.conditions:
                            for c in current_service.conditions:
                                state_icon = "[OK]" if c.state.name == "CONDITION_SUCCEEDED" else "[...]"
                                if c.state.name == "CONDITION_FAILED": state_icon = "[FAIL]"
                                conditions_log.append(f"{state_icon} {c.type}: {c.message or 'OK'}")
                        
                        await progress_callback({
                            'stage': 'cloud_deployment',
                            'progress': int(progress),
                            'message': f"{status_msg} ({int(progress)}%)",
                            'details': conditions_log or [
                                f"Service: {unique_service_name}",
                                f"Region: {self.region}",
                                f"Elapsed: {poll_count * 4}s"
                            ]
                        })
                    
                    # Note: We must wait for the operation to be truly done.
                    # On re-deployments, current_service.uri already exists, so don't break on it.
                    pass
                        
                except Exception as e:
                    self.logger.warning(f"Failed to refresh service status: {e}")
                
                if operation.done():
                    # FINAL REFRESH to get the latest URI
                    current_service = await asyncio.to_thread(
                        self.run_client.get_service,
                        name=service_path
                    )
                    
                    # Check for immediate operation failure
                    if operation.exception():
                        raise operation.exception()
                    break
            
            # 5. Result Verification
            deploy_result = await asyncio.to_thread(operation.result)
            service_url = deploy_result.uri
            
            if not service_url:
                 # Backup: try to get from current_service
                 service_url = current_service.uri
            
            if not service_url:
                 raise Exception("Deployment finished but no URI was produced.")
                 
            self.metrics.setdefault('deploys', {'success': 0, 'failure': 0})
            self.metrics['deploys']['success'] += 1
            self.logger.info(f"[SUCCESS] Deployed to: {service_url}")
            
            #  CRITICAL: Allow unauthenticated access (allUsers:roles/run.invoker)
            try:
                from google.iam.v1 import iam_policy_pb2, policy_pb2
                
                # Get current policy
                policy = await asyncio.to_thread(
                    self.run_client.get_iam_policy,
                    request={"resource": service_path}
                )
                
                # Check if allUsers:roles/run.invoker is already there
                has_invoker = False
                for binding in policy.bindings:
                    if binding.role == "roles/run.invoker" and "allUsers" in binding.members:
                        has_invoker = True
                        break
                
                if not has_invoker:
                    print(f"[GCloud] Granting public access to {unique_service_name}...")
                    new_binding = policy_pb2.Binding(
                        role="roles/run.invoker",
                        members=["allUsers"]
                    )
                    policy.bindings.append(new_binding)
                    
                    await asyncio.to_thread(
                        self.run_client.set_iam_policy,
                        request={
                            "resource": service_path,
                            "policy": policy
                        }
                    )
                    print(f"[GCloud] Public access granted successfully")
                    
                    #  CRITICAL FIX: Wait for IAM propagation
                    # IAM changes can take 15-60 seconds to propagate
                    import aiohttp
                    
                    if progress_callback:
                        await progress_callback({
                            'type': 'thought',
                            'content': "Synthesizing global IAM policy for secure public access...",
                        })
                        await progress_callback({
                            'stage': 'cloud_deployment',
                            'progress': 92,
                            'message': 'Waiting for public access propagation...'
                        })
                    
                    iam_propagated = False
                    max_iam_wait_attempts = 12  # 60 seconds max
                    
                    for iam_attempt in range(max_iam_wait_attempts):
                        # [FAANG] Emergency Abort Check
                        if abort_event and abort_event.is_set():
                            print(f"[GCloudService] üõë IAM wait ABORTED")
                            return {'success': False, 'error': 'Aborted'}

                        try:
                            async with aiohttp.ClientSession() as session:
                                async with session.get(
                                    service_url,
                                    timeout=aiohttp.ClientTimeout(total=8),
                                    allow_redirects=True
                                ) as response:
                                    if response.status != 403:
                                        iam_propagated = True
                                        self.logger.info(f"IAM propagated after {(iam_attempt + 1) * 5}s (status: {response.status})")
                                        break
                        except Exception as iam_err:
                            self.logger.debug(f"IAM propagation check failed: {iam_err}")
                        
                        if iam_attempt < max_iam_wait_attempts - 1:
                            await asyncio.sleep(5)
                            if progress_callback:
                                progress_pct = 92 + (iam_attempt * 0.3)
                                await progress_callback({
                                    'stage': 'cloud_deployment',
                                    'progress': min(progress_pct, 94),
                                    'message': f'Waiting for public access... ({(iam_attempt + 1) * 5}s)'
                                })
                    
                    
                    # [FAANG] Parallel Snapshot Trigger
                    # Trigger capture immediately as URL becomes public
                    if on_url_ready:
                        try:
                            if asyncio.iscoroutinefunction(on_url_ready):
                                asyncio.create_task(on_url_ready(service_url))
                            else:
                                on_url_ready(service_url)
                        except Exception as wrap_err:
                            self.logger.warning(f"Failed to trigger on_url_ready handle: {wrap_err}")

                    if not iam_propagated:
                        self.logger.warning("IAM propagation may be slow. URL should work shortly.")
                        
            except Exception as e:
                self.logger.warning(f"Failed to set IAM policy (non-fatal): {e}")
            
            if progress_callback:
                await progress_callback({
                    'stage': 'cloud_deployment',
                    'progress': 95,
                    'message': '[INFO] Verifying deployment health...'
                })
            
            # FIX GAP #1: Deployment verification & health checks
            health_status = await self._verify_deployment_health(
                service_url,
                unique_service_name,
                progress_callback
            )
            
            if not health_status['healthy']:
                self.logger.warning(f"Health check warning: {health_status.get('message')}")
                # Non-fatal - service might still be starting
            
            if progress_callback:
                await progress_callback({
                    'stage': 'cloud_deployment',
                    'status': 'success', # [FIX] CRITICAL: Final termination signal
                    'progress': 100,
                    'message': f'[SUCCESS] Deployment complete!',
                    'details': [
                        f'Service: {unique_service_name}',
                        f'URL: {service_url}',
                        'Health check: Verified'
                    ]
                })
            
            self.logger.info(f"Deployment successful: {service_url}")
            
            # Phase 3: Custom Domain Prep (Serverless NEG)
            # Only if enabled via config to prevent errors on projects without Compute API
            if os.getenv('ENABLE_CUSTOM_DOMAINS', 'false').lower() == 'true':
                 asyncio.create_task(self._ensure_serverless_neg(unique_service_name))

            return {
                'success': True,
                'service_name': unique_service_name,
                'url': service_url,  #  Use REAL Cloud Run URL that actually works!
                'gcp_url': service_url,  # Same for now, until custom domains are set up
                'region': self.region,
                'message': f'[SUCCESS] Deployed successfully! Your app is live at {service_url}'
            }
                
        except Exception as e:
            self.logger.error(f"Deployment failed: {str(e)}")
            
            # TRY TO CAPTURE THE FAILING REVISION FOR DIAGNOSTICS
            latest_rev = None
            try:
                # current_service might have been updated in the loop
                tmp_service = await asyncio.to_thread(
                    self.run_client.get_service,
                    name=service_path
                )
                if tmp_service and tmp_service.latest_created_revision:
                    latest_rev = tmp_service.latest_created_revision.split('/')[-1]
            except:
                pass

            #  CRITICAL FIX: Humanize error messages for better UX
            humanized = self._humanize_deployment_error(str(e))
            
            return {
                'success': False,
                'service_name': unique_service_name, # Critical for log fetching
                'latest_revision': latest_rev,       #  Precision Diagnostic Hook
                'error': humanized['message'],
                'remediation': humanized['remediation']
            }
            
    async def delete_service(self, service_name: str) -> bool:
        """
        [FAANG] Remote Resource Cleanup
        Soft-delete a Cloud Run service to prevent quota seepage.
        """
        try:
            from google.cloud import run_v2
            
            if not self.run_client:
                 self.run_client = run_v2.ServicesClient()
                 
            name = f"projects/{self.project_id}/locations/{self.region}/services/{service_name}"
            
            self.logger.info(f"[GCloudService] üóëÔ∏è Deleting remote service: {service_name}")
            
            operation = await asyncio.to_thread(
                self.run_client.delete_service,
                name=name
            )
            
            # We don't necessarily need to wait for the operation to finish, 
            # but let's confirm it started.
            if operation:
                self.logger.info(f"[SUCCESS] Remote deletion initiated for {service_name}")
                return True
            return False
            
        except google_exceptions.NotFound:
            self.logger.info(f"[GCloudService] ‚ÑπÔ∏è Service {service_name} already purged from Cloud Run.")
            return True
        except Exception as e:
            self.logger.warning(f"[GCloudService] ‚ö†Ô∏è Remote deletion failed for {service_name}: {e}")
            return False

    async def list_cloud_run_services(self):
        """
        [FAANG] Service Discovery
        List all active Cloud Run services in the project/region.
        Used for dashboard hydration and state reconciliation.
        """
        try:
            from google.cloud import run_v2
            
            # Ensure client is ready
            if not self.run_client:
                 self.run_client = run_v2.ServicesClient()
                 
            request = run_v2.ListServicesRequest(
                parent=f"projects/{self.project_id}/locations/{self.region}"
            )
            
            # Make the request using asyncio.to_thread for safety
            page_result = await asyncio.to_thread(
                self.run_client.list_services, 
                request=request
            )
            
            services = []
            for service in page_result:
                # [FAANG FIX] Correct attribute access and parsing
                s_name = service.name.split('/')[-1]
                services.append({
                    'name': s_name,
                    'url': service.uri,
                    'region': self.region,
                    'status': service.terminal_condition.state.name if service.terminal_condition else 'UNKNOWN',
                    'create_time': service.create_time.isoformat() if service.create_time else None
                })
                
            return services
            
        except Exception as e:
            self.logger.error(f"[GCloudService] List services failure: {str(e)}")
            return []

    # ========================================================================
    # CUSTOM DOMAIN MANAGEMENT (v1 API)
    # ========================================================================

    def _get_run_v1_client(self):
        """Lazy initialization of Google API Client for Cloud Run v1 (Domain Mappings)"""
        from googleapiclient import discovery
        return discovery.build('run', 'v1', cache_discovery=False)

    async def create_domain_mapping(self, service_name: str, domain_name: str, force_override: bool = False):
        """
        Create a custom domain mapping for a Cloud Run service.
        Uses the v1 API because v2 doesn't support this yet.
        """
        try:
            api = self._get_run_v1_client()
            parent = f"namespaces/{self.project_id}"
            
            body = {
                "apiVersion": "domains.cloudrun.com/v1",
                "kind": "DomainMapping",
                "metadata": {
                    "name": domain_name,
                    "namespace": self.project_id
                },
                "spec": {
                    "routeName": service_name,
                    "forceOverride": force_override
                }
            }
            
            print(f"[GCloudService] Creating domain mapping: {domain_name} -> {service_name}")
            response = await asyncio.to_thread(
                api.namespaces().domainmappings().create(
                    parent=parent,
                    body=body
                ).execute
            )
            
            return {
                "status": "created",
                "domain": domain_name,
                "records": self._extract_dns_records(response)
            }
            
        except Exception as e:
            print(f"[GCloudService] Domain mapping failed: {e}")
            return {"status": "error", "message": str(e)}

    async def list_domain_mappings(self, service_name: Optional[str] = None):
        """List verified domains for the project or specific service"""
        try:
            api = self._get_run_v1_client()
            parent = f"namespaces/{self.project_id}"
            
            response = await asyncio.to_thread(
                api.namespaces().domainmappings().list(parent=parent).execute
            )
            
            mappings = []
            for item in response.get('items', []):
                route_name = item.get('spec', {}).get('routeName')
                
                # Filter by service if requested
                if service_name and route_name != service_name:
                    continue
                    
                mappings.append({
                    "domain": item['metadata']['name'],
                    "service": route_name,
                    "created_at": item['metadata'].get('creationTimestamp'),
                    "records": self._extract_dns_records(item),
                    "status": self._get_mapping_status(item)
                })
                
            return mappings
        except Exception as e:
            print(f"[GCloudService] List domains failed: {e}")
            return []

    async def delete_domain_mapping(self, domain_name: str):
        """Remove a custom domain mapping"""
        try:
            api = self._get_run_v1_client()
            name = f"namespaces/{self.project_id}/domainmappings/{domain_name}"
            
            await asyncio.to_thread(
                api.namespaces().domainmappings().delete(name=name).execute
            )
            return True
        except Exception as e:
            print(f"[GCloudService] Delete domain failed: {e}")
            return False

    def _extract_dns_records(self, mapping):
        """Extract DNS records from a domain mapping response"""
        records = []
        status = mapping.get('status', {})
        resource_records = status.get('resourceRecords', [])
        
        for rec in resource_records:
            records.append({
                "type": rec.get('type', 'CNAME'),
                "name": rec.get('name', ''),
                "rrdata": rec.get('rrdata', '')
            })
            
        return records

    def _get_mapping_status(self, mapping):
        """Parse domain mapping status"""
        status = mapping.get('status', {})
        conditions = status.get('conditions', [])
        
        for cond in conditions:
            if cond.get('type') == 'Ready':
                return 'verified' if cond.get('status') == 'True' else 'pending'
                
        return 'unknown'
    
    async def _verify_deployment_health(
        self,
        service_url: str,
        service_name: str,
        progress_callback: Optional[Callable] = None
    ) -> Dict:
        """
         FIX GAP #1: Verify Cloud Run deployment is healthy and responding
        
        FAANG-Level Health Check Strategy:
        1. Wait for service to become available (with timeout)
        2. Test root endpoint or health endpoint
        3. Verify service is accepting requests
        4. Return comprehensive health status
        """
        try:
            import requests
            
            max_wait_seconds = 120  # 2 minutes max wait
            check_interval = 5  # Check every 5 seconds
            start_time = time.time()
            
            self.logger.info(f"Starting health check for {service_name} at {service_url}")
            
            # Try multiple endpoints in order of preference
            endpoints_to_check = [
                ('/', 'Root endpoint'),
                ('/health', 'Health endpoint'),
                ('/api/health', 'API health endpoint'),
            ]
            
            last_error = None
            
            while time.time() - start_time < max_wait_seconds:
                elapsed = int(time.time() - start_time)
                
                if progress_callback and elapsed % 15 == 0:  # Update every 15 seconds
                    await progress_callback({
                        'stage': 'cloud_deployment',
                        'progress': 95,
                        'message': f'[WAIT] Waiting for service to be ready... ({elapsed}s)',
                        'details': [f'Health check in progress for {service_name}... ({elapsed}s elapsed)']
                    })
                
                # Try each endpoint
                for endpoint, description in endpoints_to_check:
                    try:
                        health_url = f"{service_url}{endpoint}"
                        
                        response = await asyncio.to_thread(
                            requests.get,
                            health_url,
                            timeout=10,
                            allow_redirects=True
                        )
                        
                        # Accept any non-5xx status code as "service is running"
                        # 200 = OK, 404 = No route (but service is up), 401/403 = Auth required (service is up)
                        if response.status_code < 500:
                            self.logger.info(f"[SUCCESS] Health check passed: {description} returned {response.status_code}")
                            
                            return {
                                'healthy': True,
                                'status_code': response.status_code,
                                'endpoint': endpoint,
                                'message': f'Service is responding ({response.status_code})',
                                'elapsed_seconds': int(time.time() - start_time)
                            }
                    
                    except requests.exceptions.RequestException as e:
                        last_error = str(e)
                        self.logger.debug(f"Health check attempt failed for {endpoint}: {e}")
                        continue
                
                # Wait before next check
                await asyncio.sleep(check_interval)
            
            # Timeout reached
            self.logger.warning(f"Health check timeout after {max_wait_seconds}s. Last error: {last_error}")
            
            return {
                'healthy': False,
                'message': f'Service did not respond within {max_wait_seconds}s. It may still be starting up.',
                'last_error': last_error,
                'elapsed_seconds': int(time.time() - start_time)
            }
            
        except Exception as e:
            self.logger.error(f"Health check error: {e}")
            return {
                'healthy': False,
                'message': f'Health check failed: {str(e)}',
                'error': str(e)
            }
    
    def _humanize_deployment_error(self, error: str) -> Dict:
        """
         CRITICAL FIX: Convert technical errors to user-friendly messages with remediation
        
        This is essential for good UX - users shouldn't see raw GCP API errors.
        """
        error_lower = error.lower()
        
        # Container startup failures
        if 'container failed to start' in error_lower or 'port' in error_lower.replace('report', ''):
            return {
                'message': 'Your container failed to start. This usually means the application crashed during startup or is not listening on the expected port.',
                'remediation': [
                    'Check that your app binds to the PORT environment variable (Cloud Run sets this)',
                    'Verify your start command is correct in package.json or Dockerfile CMD',
                    'Add logging/console output to debug startup issues',
                    'Check for missing environment variables your app requires',
                    'Ensure all dependencies are installed in your Dockerfile'
                ]
            }
        
        # Permission issues
        if 'permission denied' in error_lower or '403' in error_lower or 'forbidden' in error_lower:
            return {
                'message': 'Permission denied while accessing Google Cloud resources.',
                'remediation': [
                    'The Cloud Run service account may need additional permissions',
                    'Ensure Cloud Run API and Cloud Build API are enabled',
                    'Verify billing is active on the project',
                    'Contact support if the issue persists'
                ]
            }
        
        # Image not found
        if 'image not found' in error_lower or 'manifest unknown' in error_lower or 'not found in registry' in error_lower:
            return {
                'message': 'The container image could not be found. The build may have failed.',
                'remediation': [
                    'Check Cloud Build logs for build errors',
                    'Verify the Artifact Registry repository exists',
                    'Try re-deploying to trigger a fresh build',
                    'Check if there were Dockerfile syntax errors'
                ]
            }
        
        # Timeout errors
        if 'timeout' in error_lower or 'deadline exceeded' in error_lower:
            return {
                'message': 'The operation timed out. This can happen with large applications or during high GCP load.',
                'remediation': [
                    'Try deploying again - Google Cloud may have been under high load',
                    'Optimize your Dockerfile to reduce build time',
                    'Consider using a smaller base image',
                    'Check if your app has very large dependencies'
                ]
            }
        
        # Quota errors
        if 'quota' in error_lower or 'resource exhausted' in error_lower or 'limit' in error_lower:
            return {
                'message': 'A Google Cloud quota or limit has been reached.',
                'remediation': [
                    'Wait a few minutes and try again',
                    'Check GCP quotas in the Cloud Console',
                    'Request a quota increase if needed',
                    'Contact support if you need higher limits'
                ]
            }
        
        # Invalid configuration
        if 'invalid' in error_lower or 'validation' in error_lower or 'malformed' in error_lower:
            return {
                'message': 'There was a configuration error in the deployment.',
                'remediation': [
                    'Check your environment variables for any typos',
                    'Verify your Dockerfile is valid',
                    'Ensure service name follows naming conventions (lowercase, hyphens only)',
                    'Check if any required fields are missing'
                ]
            }
        
        # Network errors
        if 'network' in error_lower or 'connection' in error_lower or 'dns' in error_lower:
            return {
                'message': 'A network error occurred during deployment.',
                'remediation': [
                    'Check your internet connection',
                    'Try again in a few minutes',
                    'Verify Google Cloud services are not experiencing an outage',
                    'Check https://status.cloud.google.com for service status'
                ]
            }
        
        # Default fallback
        return {
            'message': f'Deployment failed: {error}',
            'remediation': [
                'Check the error message above for specific details',
                'Try deploying again - some issues are transient',
                'Review your Dockerfile and application configuration',
                'Contact support if the issue persists'
            ]
        }
    
    async def _get_service_url(self, service_name: str) -> str:
        """Get Cloud Run service URL using API"""
        try:
            parent = f"projects/{self.project_id}/locations/{self.region}"
            service_path = f"{parent}/services/{service_name}"
            
            service = await asyncio.to_thread(
                self.run_client.get_service,
                name=service_path
            )
            
            return service.uri or f'https://{service_name}-{self.region}.run.app'
                
        except Exception as e:
            self.logger.warning(f"Could not get service URL: {e}")
            return f'https://{service_name}-{self.region}.run.app'

    async def get_service_status(self, service_name: str) -> Optional[Dict]:
        """
        Get Cloud Run service status for Guardian monitoring.
        
        Returns:
            Dict with 'status' (READY/ERROR/UNKNOWN), 'url', and optional 'error'
        """
        try:
            from google.cloud import run_v2
            
            # [FAANG] Use run_client which is already initialized in __init__
            if not self.run_client:
                 from google.cloud import run_v2
                 self.run_client = run_v2.ServicesClient()
            
            name = f"projects/{self.project_id}/locations/{self.region}/services/{service_name}"
            
            # Use asyncio.to_thread for blocking gRPC calls
            service = await asyncio.to_thread(
                self.run_client.get_service,
                name=name
            )
            
            # Map conditions to status
            terminal_condition = service.terminal_condition
            if terminal_condition and terminal_condition.type_ == "Ready":
                if terminal_condition.state == run_v2.Condition.State.CONDITION_SUCCEEDED:
                    return {'status': 'READY', 'url': service.uri}
                elif terminal_condition.state == run_v2.Condition.State.CONDITION_FAILED:
                    return {'status': 'ERROR', 'error': terminal_condition.message}
            
            return {'status': 'UNKNOWN', 'url': service.uri}
        except Exception as e:
            # self.logger.warning(f"Could not get service status for {service_name}: {e}")
            return None
    
    async def create_secret(self, secret_name: str, secret_value: str) -> Dict:
        """Create or update a secret in Secret Manager"""
        try:
            # Check if secret exists
            check_cmd = [
                'gcloud', 'secrets', 'describe', secret_name,
                '--project', self.project_id
            ]
            
            check_process = await asyncio.create_subprocess_exec(
                *check_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            await check_process.wait()
            
            if check_process.returncode == 0:
                # Secret exists, add new version
                cmd = [
                    'gcloud', 'secrets', 'versions', 'add', secret_name,
                    '--data-file=-',
                    '--project', self.project_id
                ]
            else:
                # Create new secret
                cmd = [
                    'gcloud', 'secrets', 'create', secret_name,
                    '--data-file=-',
                    '--project', self.project_id,
                    '--replication-policy', 'automatic'
                ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate(input=secret_value.encode())
            
            if process.returncode == 0:
                return {
                    'success': True,
                    'secret_name': secret_name,
                    'message': f'Secret {secret_name} created/updated'
                }
            else:
                raise Exception(stderr.decode())
                
        except Exception as e:
            return {
                'success': False,
                'error': f'Failed to create secret: {str(e)}'
            }
    
    async def get_service_logs(self, service_name: str, limit: int = 50, revision_name: Optional[str] = None) -> List[str]:
        """Fetch recent logs from Cloud Run service (SDK-Native)"""
        try:
            # Native Protocol: Use the SDK client to bypass Windows Shell/CLI issues
            def fetch_logs():
                filter_parts = [
                    'resource.type="cloud_run_revision"',
                    f'resource.labels.service_name="{service_name}"'
                ]
                
                if revision_name:
                    filter_parts.append(f'resource.labels.revision_name="{revision_name}"')
                
                # Look back 15 minutes for maximum context
                now_utc = datetime.now(timezone.utc)
                start_time = (now_utc - timedelta(minutes=15)).strftime('%Y-%m-%dT%H:%M:%SZ')
                filter_parts.append(f'timestamp>="{start_time}"')
                # Neutralize Noisy Audit Logs: We only want the container pulse
                filter_parts.append('NOT logName:"cloudaudit.googleapis.com"')
                
                filter_expr = " AND ".join(filter_parts)
                self.logger.info(f"[Diagnostic] Fetching native logs: {filter_expr}")
                
                def get_entries(expr):
                    try:
                        return self.logging_client.list_entries(
                            filter_=expr,
                            order_by=cloud_logging.DESCENDING,
                            max_results=limit
                        )
                    except Exception as e:
                        self.logger.warning(f"Native filter execution failed: {e}")
                        return []
                
                # LAYER 1: The Precision Search
                entries = get_entries(filter_expr)
                logs = []
                for entry in entries:
                    p = entry.payload
                    logs.append(f"[{entry.severity}] {entry.log_name}: {json.dumps(p) if isinstance(p, dict) else str(p)}")
                
                # LAYER 2: The Fallback (Service level)
                if not logs and revision_name:
                    self.logger.info(f"[Diagnostic] Revision logs empty. Falling back to service-level...")
                    fallback_expr = f'resource.labels.service_name="{service_name}" AND timestamp>="{start_time}"'
                    for entry in get_entries(fallback_expr):
                        p = entry.payload
                        logs.append(f"[{entry.severity}] {entry.log_name}: {json.dumps(p) if isinstance(p, dict) else str(p)}")
                
                # LAYER 3: The "Nuclear" option (Brute force string match for service)
                if not logs:
                    self.logger.info(f"[Diagnostic] Filters failed. Brute-forcing log hunt for '{service_name}'...")
                    nuclear_expr = f'"{service_name}" AND timestamp>="{start_time}"'
                    for entry in get_entries(nuclear_expr):
                        p = entry.payload
                        logs.append(f"[{entry.severity}] {entry.log_name}: {json.dumps(p) if isinstance(p, dict) else str(p)}")

                # LAYER 4: The Heartbeat Hunt (Explicit string search for our marker)
                if not logs:
                    self.logger.info(f"[Diagnostic] All service logs dark. Searching for Proprietary Heartbeat '[ServerGem]'...")
                    heartbeat_expr = f'"[ServerGem]" AND timestamp>="{start_time}"'
                    for entry in get_entries(heartbeat_expr):
                        p = entry.payload
                        logs.append(f"[{entry.severity}] {entry.log_name}: {json.dumps(p) if isinstance(p, dict) else str(p)}")

                # FINAL: Reverse and Print
                results = logs[::-1]
                
                if results:
                    self.logger.info(f"[Sovereign Log Catch] FOUND {len(results)} ENTRIES:")
                    for r in results[-20:]: # Show last 20 for maximum context
                        self.logger.info(f"  > {r}")
                else:
                    self.logger.warning(f"[Diagnostic] CRITICAL: Zero logs found for {service_name} after atomic search.")
                
                return results

            logs = await asyncio.to_thread(fetch_logs)
            return logs
                
        except Exception as e:
            self.logger.warning(f"Native SDK log fetch failed for {service_name}: {e}")
            return []

    async def _ensure_serverless_neg(self, service_name: str) -> None:
        """
        Phase 3: Create Serverless Network Endpoint Group (NEG) for Load Balancer.
        This enables Custom Domains via an External HTTP(S) Load Balancer.
        Following 'Million Dollar Blueprint' Phase 3A requirements.
        """
        neg_name = f"neg-{service_name}"
        self.logger.info(f"Phase 3: Configuring Serverless NEG '{neg_name}' for custom domains...")
        
        try:
            # 1. Check if NEG exists
            check_cmd = [
                'gcloud', 'compute', 'network-endpoint-groups', 'describe', neg_name,
                '--region', self.region,
                '--project', self.project_id
            ]
            
            proc = await asyncio.create_subprocess_exec(
                *check_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            await proc.communicate()
            
            if proc.returncode == 0:
                self.logger.info(f"Phase 3: NEG '{neg_name}' already exists.")
                return

            # 2. Create NEG
            create_cmd = [
                'gcloud', 'compute', 'network-endpoint-groups', 'create', neg_name,
                '--region', self.region,
                '--network-endpoint-type', 'serverless',
                '--cloud-run-service', service_name,
                '--project', self.project_id
            ]
            
            proc = await asyncio.create_subprocess_exec(
                *create_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await proc.communicate()
            
            if proc.returncode == 0:
                self.logger.info(f"Phase 3: Successfully created NEG '{neg_name}'.")
            else:
                self.logger.warning(f"Phase 3: Failed to create NEG (Compute API might be disabled): {stderr.decode()}")

        except Exception as e:
            self.logger.warning(f"Phase 3: Custom domain prep skipped: {e}")

    # ========================================================================
    # SECRET MANAGER INTEGRATION
    # ========================================================================

    async def create_or_update_secret(self, secret_id: str, payload: str) -> str:
        """Create or update a secret in Secret Manager"""
        if not self.secret_manager_client:
             raise Exception("Secret Manager client not initialized")
             
        parent = f"projects/{self.project_id}"
        
        # Check if secret exists
        try:
            secret_name = f"{parent}/secrets/{secret_id}"
            await asyncio.to_thread(self.secret_manager_client.get_secret, name=secret_name)
        except Exception:
            # Create secret
            await asyncio.to_thread(
                self.secret_manager_client.create_secret,
                parent=parent,
                secret_id=secret_id,
                secret={"replication": {"automatic": {}}}
            )
            
        # Add secret version
        response = await asyncio.to_thread(
            self.secret_manager_client.add_secret_version,
            parent=f"{parent}/secrets/{secret_id}",
            payload={"data": payload.encode("UTF-8")}
        )
        return response.name

    async def list_secrets(self, filter_str: Optional[str] = None) -> List[Dict]:
        """List secrets in the project"""
        if not self.secret_manager_client:
             raise Exception("Secret Manager client not initialized")
             
        parent = f"projects/{self.project_id}"
        
        # Simple list
        secrets = []
        try:
             # Use iterator
             request = {"parent": parent}
             if filter_str:
                 request["filter"] = filter_str
                 
             response = await asyncio.to_thread(
                 self.secret_manager_client.list_secrets, 
                 request=request
             )
             
             for secret in response:
                 secrets.append({
                     'name': secret.name,
                     'create_time': secret.create_time.isoformat() if secret.create_time else None,
                     'labels': dict(secret.labels)
                 })
        except Exception as e:
            self.logger.error(f"Failed to list secrets: {e}")
            
        return secrets

    # ========================================================================
    # MONITORING & METRICS
    # ========================================================================

    async def get_service_metrics(self, service_name: str, hours: int = 1) -> Dict[str, Any]:
        """Fetch Cloud Run metrics (CPU, Memory, Requests)"""
        if not self.monitoring_client:
            raise Exception("Monitoring client not initialized")
            
        project_name = f"projects/{self.project_id}"
        end_time = time.time()
        start_time = end_time - (hours * 3600)
        
        interval = monitoring_v3.TimeInterval({
            "end_time": {"seconds": int(end_time)},
            "start_time": {"seconds": int(start_time)},
        })
        
        metrics_data = {
            "cpu": [],
            "memory": [],
            "requests": []
        }
        
        async def fetch_metric(metric_type, label):
             # [FAANG] Dynamic Aggregation Strategy
             aligner = monitoring_v3.Aggregation.Aligner.ALIGN_MEAN
             reducer = monitoring_v3.Aggregation.Reducer.REDUCE_MEAN
             
             if label == 'requests':
                 aligner = monitoring_v3.Aggregation.Aligner.ALIGN_RATE
                 reducer = monitoring_v3.Aggregation.Reducer.REDUCE_SUM
             elif 'utilization' in metric_type:
                 # Ensure we use ALIGN_MEAN for double-based GAUGE metrics
                 aligner = monitoring_v3.Aggregation.Aligner.ALIGN_MEAN
                 reducer = monitoring_v3.Aggregation.Reducer.REDUCE_MEAN

             aggregation = monitoring_v3.Aggregation({
                "alignment_period": {"seconds": 60},
                "per_series_aligner": aligner,
                "cross_series_reducer": reducer,
                "group_by_fields": []
             })

             filter_str = f'metric.type="{metric_type}" AND resource.type="cloud_run_revision" AND resource.labels.service_name="{service_name}"'
             
             try:
                 results = await asyncio.to_thread(
                     self.monitoring_client.list_time_series,
                     request={
                         "name": project_name,
                         "filter": filter_str,
                         "interval": interval,
                         "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,
                         "aggregation": aggregation
                     }
                 )
                 
                 data_points = []
                 for result in results:
                     for point in result.points:
                         val = 0
                         # [FAANG] Handle value types with high precision
                         if point.value.HasField('double_value'):
                             val = point.value.double_value
                         elif point.value.HasField('int64_value'):
                             val = float(point.value.int64_value)
                         elif point.value.HasField('distribution_value'):
                             val = point.value.distribution_value.mean
                         
                         # Conversion: CPU utilization is 0-1, convert to 0-100%
                         if label == 'cpu':
                             val *= 100
                         data_points.append({
                             "timestamp": point.interval.start_time.isoformat(),
                             "value": val
                         })
                 
                 # Sorting is crucial for charting
                 data_points.sort(key=lambda x: x['timestamp'])
                 return data_points
             except Exception as e:
                 # [FAANG] Graceful Degradation: If metric missing, just return empty
                 # This prevents spamming logs for new services that don't have metrics yet
                 if "404" in str(e) or "NotFound" in str(e):
                     return [] 
                 self.logger.warning(f"Error fetching {label}: {e}")
                 return []

        try:
            # Fetch in parallel?
            # Cloud Run CPU
            # [SUCCESS] Standardized Metrics for Cloud Run v2
            # Use singular 'utilization' for double-based metrics
            metrics_data['cpu'] = await fetch_metric("run.googleapis.com/container/cpu/utilization", "cpu")
            metrics_data['memory'] = await fetch_metric("run.googleapis.com/container/memory/utilization", "memory")
            metrics_data['requests'] = await fetch_metric("run.googleapis.com/request_count", "requests")
            
        except Exception as e:
            self.logger.error(f"Failed to fetch metrics bundle: {e}")
            import traceback
            traceback.print_exc()
            
        return metrics_data


    async def _poll_build_logs(self, build_id: str, logs_bucket: str, progress_callback: Optional[Callable], last_offset: int = 0, abort_event: Optional[asyncio.Event] = None) -> int:
        """Fetch and stream new build logs from GCS"""
        if not logs_bucket or not progress_callback:
             return last_offset
             
        try:
            def fetch_delta():
                from google.cloud import storage
                import os
                
                # Silence internal google logs to keep console clean
                os.environ["GOOGLE_CLOUD_DISABLE_GRPC"] = "true" 
                
                storage_client = storage.Client(project=self.project_id)
                bucket_name = logs_bucket.replace('gs://', '').split('/')[0]
                bucket = storage_client.bucket(bucket_name)
                blob = bucket.blob(f"log-{build_id}.txt")
                
                if not blob.exists():
                    return "", last_offset
                
                # Fetch new bytes from last offset
                # download_as_bytes supports 'start'
                try:
                    content_bytes = blob.download_as_bytes(start=last_offset)
                    if not content_bytes:
                        return "", last_offset
                    
                    new_offset = last_offset + len(content_bytes)
                    return content_bytes.decode('utf-8', errors='replace'), new_offset
                except Exception as e:
                    # Often fails if file is being written to, just retry next time
                    return "", last_offset
            
            delta_text, new_offset = await asyncio.to_thread(fetch_delta)
            
            if delta_text:
                # Clean and filter lines
                lines = [line.strip() for line in delta_text.split('\n') if line.strip()]
                
                # [FAANG OPTIMIZATION] Filter out progress bars or repetitive GCP noise if needed
                # But user wants "nitty gritty", so we send most of it.
                if lines:
                    # ‚úÖ FAANG UX FIX: Inject message to satisfy app.py visibility check
                    await progress_callback({
                        'stage': 'container_build',
                        'message': 'Streaming build telemetry...', 
                        'details': lines
                    })
            return new_offset
        except Exception as e:
            # Silent fail for logs, don't crash the build loop
            return last_offset
