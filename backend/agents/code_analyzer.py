"""
Code Analyzer Agent - Framework and dependency detection
"""

import os
import json
import re
import asyncio  
from pathlib import Path
from typing import Dict, List, Optional, Callable 
import vertexai
from vertexai.generative_models import GenerativeModel


class CodeAnalyzerAgent:
    """
    Analyzes codebases using Vertex AI Gemini for intelligent framework detection
    and dependency analysis with automatic fallback to Gemini API on quota exhaustion.
    """
    
    def __init__(
        self, 
        gcloud_project: str, 
        location: str = 'us-central1',
        gemini_api_key: Optional[str] = None
    ):
        self.gemini_api_key = gemini_api_key
        self.use_vertex_ai = bool(gcloud_project)
        self.gcloud_project = gcloud_project
        
        print(f"[CodeAnalyzer] Initialization:")
        print(f"  - Vertex AI: {self.use_vertex_ai} (project: {gcloud_project})")
        print(f"  - Gemini API key available: {bool(gemini_api_key)}")
        print(f"  - Fallback ready: {self.use_vertex_ai and bool(gemini_api_key)}")
        
        if self.use_vertex_ai:
            vertexai.init(project=gcloud_project, location=location)
            self.model = GenerativeModel('gemini-3-flash-preview')  # Gemini 3 Hackathon
        else:
            # Using Gemini API directly
            import google.generativeai as genai
            genai.configure(api_key=gemini_api_key)
            self.model = genai.GenerativeModel('gemini-3-flash-preview')  # Gemini 3 Hackathon
    
    async def analyze_project(
        self, 
        project_path: str, 
        progress_notifier=None, 
        progress_callback=None, 
        skip_ai=False,
        abort_event: Optional[asyncio.Event] = None # [FAANG]
    ) -> Dict:
        """Analyze project structure and configuration with real-time progress updates"""
        
        project_path = Path(project_path)
        heuristic_report = None
        file_structure = None
        
        if progress_callback:
            await progress_callback("üîç Analyzing project structure...")
            await asyncio.sleep(0)  # ‚úÖ Force event loop flush
        if progress_notifier:
            await progress_notifier.start_stage(
                "code_analysis",
                "üîç Analyzing project structure and dependencies..."
            )
        
        if not project_path.exists():
            return {'error': 'Project path does not exist'}
        
        # Gather file information
        file_structure = self._scan_directory(project_path)
        
        # ‚úÖ PHASE 1.1: Progress - Scanning files WITH flush
        if progress_callback:
            await progress_callback(f"üìÇ Scanned {len(file_structure['files'])} files")
            await asyncio.sleep(0)  # ‚úÖ Force event loop flush
        
        # ‚úÖ PHASE 2: Enhanced Heuristic Analysis (The "Analyzer Engine")
        # We run this BEFORE relying on LLM to provide hard signals
        heuristic_report = self._heuristic_analysis(project_path, file_structure)
        
        # ‚úÖ FAST SYNC: If skip_ai is requested, return early with heuristic data
        if skip_ai:
            print(f"[CodeAnalyzer] Fast Sync triggered - skipping AI analysis for {project_path.name}")
            return {
                'language': heuristic_report.get('language', 'unknown'),
                'framework': heuristic_report.get('framework', 'unknown'),
                'confidence': heuristic_report.get('confidence', 0),
                'dependencies': [], # Heuristics don't parse full list yet
                'env_vars': self._extract_env_vars(project_path),
                'entry_point': 'Auto-detected',
                'heuristic_report': heuristic_report
            }
        # [FAANG] Emergency Abort Check
        if abort_event and abort_event.is_set():
            return {'error': 'Analysis aborted by user'}

        if progress_notifier:
            await progress_notifier.send_thought("Initializing semantic project traversal... mapping filesystem topology.")
            await progress_notifier.send_thought(f"Detected {len(file_structure['files'])} nodes. Constructing dependency graph hierarchy...")
            
            # Context-aware thoughts based on heuristics
            if heuristic_report.get('framework') != 'unknown':
                await progress_notifier.send_thought(f"Heuristic Engine isolated candidate framework: `{heuristic_report['framework']}` ({int(heuristic_report['confidence']*100)}% confidence).")
                await progress_notifier.send_thought(f"Parsing AST and manifest files to validate `{heuristic_report['framework']}` signatures...")
            
            await progress_notifier.send_thought("Scanning entry points for specific Cloud Run compatibility signatures...")
            await progress_notifier.send_thought("Calculating memory overhead and CPU requirements from package ecosystem...")
            
        # Use Gemini to intelligently analyze the project, feeding it heuristic signals
        analysis_prompt = self._build_analysis_prompt(file_structure, project_path, heuristic_report)
        
        # ‚úÖ PHASE 1.1: Progress - Analyzing with AI WITH flush
        if progress_callback:
            if heuristic_report['confidence'] > 0.8:
                await progress_callback(f"üß† Engine detected {heuristic_report['framework']} ({int(heuristic_report['confidence']*100)}% confidence)")
                await asyncio.sleep(0)
            await progress_callback("ü§ñ AI analyzing code structure...")
            await asyncio.sleep(0)  # ‚úÖ Force event loop flush
        if progress_notifier:
            await progress_notifier.update_progress(
                "code_analysis",
                "ü§ñ Using AI to confirm framework and dependencies...",
                30
            )
        
        try:
            # Try with current model (Vertex AI or Gemini API)
            if self.use_vertex_ai:
                response = await self.model.generate_content_async(analysis_prompt)
            else:
                # Gemini API uses synchronous method
                response = self.model.generate_content(analysis_prompt)
            
            # Properly extract text from Gemini response
            response_text = None
            if hasattr(response, 'text') and response.text:
                response_text = response.text
            elif hasattr(response, 'candidates') and response.candidates:
                parts = response.candidates[0].content.parts
                if parts:
                    response_text = ''.join([part.text for part in parts if hasattr(part, 'text')])
            
            if not response_text:
                print("[CodeAnalyzer] No text in Gemini response, using fallback")
                return self._fallback_analysis(project_path, file_structure, heuristic_report)
            
            # Extract JSON from response (handle markdown code blocks)
            response_text = response_text.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            analysis = json.loads(response_text)
            
            # ‚úÖ GROUND TRUTH PROTECTION: Don't let AI override 100% confident heuristics
            if heuristic_report.get('confidence', 0) >= 1.0:
                print(f"[CodeAnalyzer] Protecting ground truth: {heuristic_report['framework']}")
                analysis['framework'] = heuristic_report['framework']
                if 'language' in heuristic_report:
                    analysis['language'] = heuristic_report['language']
            
            # Enhance with static analysis
            analysis['env_vars'] = self._extract_env_vars(project_path)
            analysis['dockerfile_exists'] = (project_path / 'Dockerfile').exists()
            
            # ‚úÖ MERGE: Combine Heuristic Runtime + AI Intelligence
            if heuristic_report.get('runtime_version') and not analysis.get('runtime_version'):
                analysis['runtime_version'] = heuristic_report['runtime_version']
            
            # Ensure language is NEVER unknown if we have a better guess
            if (analysis.get('language') == 'unknown' or not analysis.get('language')) and 'language' in heuristic_report:
                analysis['language'] = heuristic_report['language']

            # ‚úÖ PHASE 1.1: Progress - Analysis complete WITH flush
            if progress_callback:
                await progress_callback(f"‚úÖ Detected {analysis.get('framework', 'unknown')} framework")
                await asyncio.sleep(0)  # ‚úÖ Force event loop flush
            if progress_notifier:
                await progress_notifier.complete_stage(
                    "code_analysis",
                    f"‚úÖ Project analyzed: {analysis.get('framework', 'unknown')} application",
                    details={
                        'framework': analysis.get('framework', 'unknown'),
                        'language': analysis.get('language', 'unknown'),
                        'dependencies': len(analysis.get('dependencies', [])),
                        'env_vars': len(analysis.get('env_vars', []))
                    }
                )
            
            return analysis
            
        except Exception as e:
            error_msg = str(e)
            print(f"[CodeAnalyzer] Error: {error_msg}")
            
            # ‚úÖ Check for quota/resource exhausted error
            from google.api_core.exceptions import ResourceExhausted
            is_quota_error = isinstance(e, ResourceExhausted) or any(keyword in error_msg.lower() for keyword in [
                'resource exhausted', '429', 'quota', 'rate limit'
            ])
            
            if is_quota_error and self.use_vertex_ai and self.gemini_api_key:
                # Fallback to direct Gemini API if Vertex AI fails due to quota
                print("[CodeAnalyzer] Quota exhausted on Vertex AI, attempting direct Gemini API...")
                try:
                    import google.generativeai as genai
                    genai.configure(api_key=self.gemini_api_key)
                    fallback_model = genai.GenerativeModel('gemini-3-flash-preview')  # Gemini 3 Hackathon
                    response = fallback_model.generate_content(analysis_prompt)
                    # [Truncated logic for brevity - actually we should probably just call fallback_analysis for safety]
                    return self._fallback_analysis(project_path, file_structure, heuristic_report)
                except Exception as fallback_err:
                    print(f"[CodeAnalyzer] Fallback failed: {fallback_err}")
            
            return self._fallback_analysis(project_path, file_structure, heuristic_report)
    
    def _scan_directory(self, path: Path, max_depth: int = 3) -> Dict:
        """Scan directory structure and collect deep metrics"""
        
        exclude_dirs = {
            'node_modules', 'venv', '__pycache__', '.git', 
            'dist', 'build', 'target', 'vendor', '.next', '.cache'
        }
        
        source_extensions = {
            '.js', '.ts', '.tsx', '.jsx', '.py', '.go', '.rs', 
            '.java', '.c', '.cpp', '.h', '.hpp', '.rb', '.php', '.css', '.scss'
        }
        
        structure = {
            'files': [],
            'directories': [],
            'config_files': [],
            'metrics': {
                'total_files': 0,
                'total_lines': 0,
                'total_size_kb': 0,
                'extension_map': {}
            }
        }
        
        config_patterns = [
            'package.json', 'requirements.txt', 'go.mod', 'pom.xml',
            'Gemfile', 'composer.json', '.env', 'Dockerfile',
            'docker-compose.yml', 'app.yaml', 'cloudbuild.yaml',
            'tsconfig.json', 'vite.config.ts', 'next.config.js'
        ]
        
        for item in path.rglob('*'):
            # Skip excluded directories
            if any(excluded in item.parts for excluded in exclude_dirs):
                continue
            
            if item.is_file():
                rel_path = str(item.relative_to(path))
                structure['files'].append(rel_path)
                
                # File count and size
                structure['metrics']['total_files'] += 1
                try:
                    file_size = item.stat().st_size
                    structure['metrics']['total_size_kb'] += file_size / 1024
                except:
                    pass
                
                # Extension map
                ext = item.suffix.lower() or 'no-ext'
                structure['metrics']['extension_map'][ext] = structure['metrics']['extension_map'].get(ext, 0) + 1
                
                # Line Count (only for source files)
                if ext in source_extensions:
                    structure['metrics']['total_lines'] += self._get_line_count(item)
                
                if item.name in config_patterns:
                    structure['config_files'].append(rel_path)
        
        # Round size
        structure['metrics']['total_size_kb'] = round(structure['metrics']['total_size_kb'], 2)
        
        return structure

    def _get_line_count(self, file_path: Path) -> int:
        """Efficiently count lines in a file"""
        try:
            with open(file_path, 'rb') as f:
                return sum(1 for _ in f)
        except:
            return 0
    
    def _heuristic_analysis(self, project_path: Path, file_structure: Dict) -> Dict:
        """
        FAANG-Level Static Analysis Engine
        Uses weighted signals to determine framework, language, and runtime with high confidence
        BEFORE checking with the LLM.
        """
        
        # 1. Initialize Scoreboard
        framework_scores = {}
        detected_signals = []
        
        def add_score(framework, points, reason):
            framework_scores[framework] = framework_scores.get(framework, 0) + points
            detected_signals.append(f"{framework}: {reason} (+{points})")

        # 2. Dependency Scanning
        deps = {}
        dev_deps = {}
        scripts = {}
        engines = {}
        
        if 'package.json' in file_structure['config_files']:
            try:
                pkg = json.loads((project_path / 'package.json').read_text())
                deps = pkg.get('dependencies', {})
                dev_deps = pkg.get('devDependencies', {})
                scripts = pkg.get('scripts', {})
                engines = pkg.get('engines', {})
            except: pass
            
            # Node Frameworks
            if '@nestjs/core' in deps: add_score('nestjs', 100, 'Core dependency')
            if 'next' in deps: add_score('nextjs', 100, 'Core dependency')
            if 'express' in deps: add_score('express', 50, 'Core dependency')
            if '@remix-run/node' in deps: add_score('remix', 100, 'Core dependency')
            if '@sveltejs/kit' in dev_deps: add_score('sveltekit', 100, 'Dev dependency')
            if 'astro' in deps: add_score('astro', 100, 'Core dependency')
            if 'fastify' in deps: add_score('fastify', 80, 'Core dependency')
            if 'fastify' in deps: add_score('fastify', 80, 'Core dependency')
            if 'vue' in deps and 'nuxt' in deps: add_score('nuxtjs', 100, 'Core dependency')
            
            # Generic Frontend Detection (Angular, Vue, Svelte, React, etc.)
            # If no meta-framework (Next/Nuxt) is found, but frontend libs exist
            if 'react' in deps or 'react' in dev_deps:
                # [FAANG] Report 'react' as primary framework, track build tool as metadata
                add_score('react', 100, 'React detected as primary framework')
                if 'vite' in deps or 'vite' in dev_deps:
                    add_score('react', 10, 'Vite build tool bonus')  # Boost React score
                elif 'react-scripts' in deps or 'react-scripts' in dev_deps:
                    add_score('react', 10, 'CRA build tool bonus')  # Boost React score

            frontend_libs = ['@angular/core', 'vue', 'svelte'] 
            if any(lib in deps or lib in dev_deps for lib in frontend_libs):
                # Only add if no specific framework claimed it yet
                if not any(f in framework_scores for f in ['nextjs', 'nuxtjs', 'sveltekit', 'remix', 'astro', 'react']):
                     add_score('frontend_generic', 60, 'Frontend library detected')

        if 'requirements.txt' in file_structure['config_files']:
            reqs = (project_path / 'requirements.txt').read_text()
            if 'fastapi' in reqs: add_score('fastapi', 100, 'Core dependency')
            if 'flask' in reqs: add_score('flask', 80, 'Core dependency')
            if 'django' in reqs: add_score('django', 100, 'Core dependency')
            
        if 'go.mod' in file_structure['config_files']:
            gomod = (project_path / 'go.mod').read_text()
            if 'github.com/gin-gonic/gin' in gomod: add_score('gin', 100, 'Core dependency')
            if 'github.com/labstack/echo' in gomod: add_score('echo', 100, 'Core dependency')
            if 'github.com/gofiber/fiber' in gomod: add_score('fiber', 100, 'Core dependency')
            if 'github.com/gobuffalo/buffalo' in gomod: add_score('buffalo', 100, 'Core dependency')
            if 'github.com/gobuffalo/buffalo' in gomod: add_score('buffalo', 100, 'Core dependency')
            # Fallback for generic Go
            if not framework_scores.get('gin') and not framework_scores.get('echo'):
                add_score('go_generic', 50, 'Go module detected')

        # PHP Composer
        if 'composer.json' in file_structure['config_files']:
            try:
                composer = json.loads((project_path / 'composer.json').read_text())
                reqs = composer.get('require', {})
                if 'laravel/framework' in reqs: add_score('laravel', 100, 'Core dependency')
                if 'symfony/framework-bundle' in reqs: add_score('symfony', 100, 'Core dependency')
                if not framework_scores.get('laravel') and not framework_scores.get('symfony'):
                     add_score('php_generic', 50, 'Composer detected')
            except: 
                pass

        # Java Maven
        if 'pom.xml' in file_structure['config_files']:
            pom = (project_path / 'pom.xml').read_text()
            if 'spring-boot-starter-web' in pom: add_score('springboot', 100, 'Starter dependency')
            else: add_score('java_generic', 50, 'Maven detected')

        # Ruby Gemfile
        if 'Gemfile' in file_structure['config_files']:
            gemfile = (project_path / 'Gemfile').read_text()
            if "gem 'rails'" in gemfile or 'gem "rails"' in gemfile: add_score('rails', 100, 'Rails gem')
            else: add_score('ruby_generic', 50, 'Gemfile detected')
            
        # 3. File Pattern Scanning
        if (project_path / 'nest-cli.json').exists(): add_score('nestjs', 50, 'Config file')
        if (project_path / 'next.config.js').exists(): add_score('nextjs', 50, 'Config file')
        if (project_path / 'remix.config.js').exists(): add_score('remix', 50, 'Config file')
        if (project_path / 'svelte.config.js').exists(): add_score('sveltekit', 50, 'Config file')
        if (project_path / 'astro.config.mjs').exists(): add_score('astro', 50, 'Config file')
        if (project_path / 'artisan').exists(): add_score('laravel', 100, 'Entry file')
        if (project_path / 'manage.py').exists(): add_score('django', 50, 'Entry file')

        # 4. Determine Winner
        if not framework_scores:
            # Language fallback if no framework detected
            lang = 'python' if (project_path / 'requirements.txt').exists() or list(project_path.glob('*.py')) else \
                   'node' if (project_path / 'package.json').exists() or list(project_path.glob('*.js')) else \
                   'golang' if (project_path / 'go.mod').exists() or list(project_path.glob('*.go')) else 'unknown'
            return {
                'framework': 'unknown', 
                'language': lang, 
                'port': self._detect_port(project_path, file_structure),
                'confidence': 0, 
                'signals': []
            }
            
        winner = max(framework_scores, key=framework_scores.get)
        total_score = framework_scores[winner]
        confidence = min(total_score / 100.0, 1.0) # Cap at 1.0
        
        # 5. Language Inference
        language = 'node' if winner in ['express', 'nestjs', 'nextjs', 'remix', 'sveltekit', 'astro', 'fastify', 'nuxtjs', 'frontend_generic', 'vite', 'cra', 'react'] else \
                   'python' if winner in ['fastapi', 'flask', 'django'] else \
                   'golang' if winner in ['gin', 'echo', 'fiber', 'buffalo', 'go_generic'] else \
                   'php' if winner in ['laravel', 'symfony', 'php_generic'] else \
                   'ruby' if winner in ['rails', 'ruby_generic'] else \
                   'java' if winner == 'springboot' else 'unknown'
        
        # 6. Metadata Extraction
        runtime_version = engines.get('node') or engines.get('python') or 'unknown'
        
        is_monorepo = any(f in file_structure['files'] for f in ['pnpm-workspace.yaml', 'lerna.json', 'turbo.json'])
        
        # [FAANG] Detect build tool separately for React projects
        build_tool = None
        if winner == 'react':
            if 'vite' in deps or 'vite' in dev_deps:
                build_tool = 'vite'
            elif 'react-scripts' in deps or 'react-scripts' in dev_deps:
                build_tool = 'cra'
        # [FAANG] Determine build_output based on framework and build tool
        if winner == 'react':
            build_output = 'dist' if build_tool == 'vite' else 'build'
        elif winner in ['nestjs', 'vite']:
            build_output = 'dist'
        elif winner == 'cra':
            build_output = 'build'
        elif winner == 'nextjs':
            build_output = '.next'
        else:
            build_output = 'build'
        
        return {
            'framework': winner,
            'language': language,
            'confidence': confidence,
            'signals': detected_signals,
            'runtime_version': runtime_version,
            'build_tool': build_tool,
            'is_monorepo': is_monorepo,
            'build_output': build_output,
            'port': self._detect_port(project_path, file_structure),
            'scores': framework_scores
        }

        
    def _build_analysis_prompt(self, file_structure: Dict, project_path: Path, heuristic_report: Dict = None) -> str:
        """Build analysis prompt for Gemini with Heuristic Intelligence"""
        
        # Read key configuration files
        config_contents = {}
        for config_file in file_structure['config_files'][:10]:  # Limit to first 10
            try:
                full_path = project_path / config_file
                if full_path.stat().st_size < 50000:  # Only read files < 50KB
                    config_contents[config_file] = full_path.read_text()
            except:
                continue
        
        heuristic_text = ""
        if heuristic_report and heuristic_report['confidence'] > 0.5:
            heuristic_text = f"""
**üîç HEURISTIC ENGINE FINDINGS (Confidence: {int(heuristic_report['confidence']*100)}%):**
- Detected Framework: {heuristic_report['framework']}
- Signals: {', '.join(heuristic_report['signals'])}
- Monorepo: {heuristic_report['is_monorepo']}
- Runtime: {heuristic_report.get('runtime_version')}
- Recommended Build Output: {heuristic_report.get('build_output')}

Please VALIDATE these findings. If strong evidence suggests otherwise, override them.
"""

        prompt = f"""
Analyze this software project and return a JSON object with deployment information.
Be extremely detailed in your recommendations and warnings based on the technical magnitude of the project.

{heuristic_text}

**File Structure & Metrics:**
{json.dumps(file_structure, indent=2)}

**Configuration Files:**
{json.dumps(config_contents, indent=2)}

**Return JSON in this exact format:**
{{
  "language": "python|nodejs|golang|java|ruby|php",
  "framework": "express|nestjs|koa|hapi|fastify|flask|django|fastapi|nextjs|nuxtjs|gin|echo|fiber|springboot|rails|laravel|phoenix|strapi|adonis|remix|sveltekit|astro",
  "entry_point": "main file (e.g., app.py, index.js, main.go, src/main.ts)",
  "port": 8080,
  "health_check_path": "URL path for health checks (e.g., /, /health, /api/ping)",
  "health_check_type": "http|tcp",
  "memory_limit": "recommended RAM (e.g., 512Mi, 1Gi, 2Gi)",
  "cpu_limit": "recommended CPU (e.g., 1, 2)",
  "runtime_version": "e.g., nodejs:18, python:3.9 (infer from engines/config)",
  "dependencies": [
    {{"name": "package-name", "version": "1.0.0"}}
  ],
  "database": "postgresql|mysql|mongodb|redis|firestore|none",
  "build_tool": "npm|pip|go|maven|gradle|bundle",
  "build_output": "folder for static assets (dist|build|out|target)",
  "start_command": "command to start the application",
  "metrics": {{
    "total_files": {file_structure['metrics']['total_files']},
    "total_lines": {file_structure['metrics']['total_lines']},
    "total_size_kb": {file_structure['metrics']['total_size_kb']},
    "extension_map": {json.dumps(file_structure['metrics']['extension_map'])}
  }},
  "readiness_score": 0-100,
  "verdict": "A detailed 1-sentence strategic verdict on deployment readiness",
  "recommendations": [
    "deployment recommendation 1",
    "deployment recommendation 2"
  ],
  "warnings": [
    "potential issue 1",
    "potential issue 2"
  ]
}}

Return ONLY valid JSON, no markdown or explanations.
"""
        
        return prompt
    
    def _extract_env_vars(self, project_path: Path) -> List[str]:
        """Extract environment variables from .env files"""
        
        env_vars = []
        env_files = ['.env', '.env.example', '.env.sample']
        
        for env_file in env_files:
            env_path = project_path / env_file
            if env_path.exists():
                try:
                    content = env_path.read_text()
                    for line in content.split('\n'):
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            var_name = line.split('=')[0].strip()
                            env_vars.append(var_name)
                except:
                    continue
        
        return list(set(env_vars))  # Remove duplicates
    
    def _fallback_analysis(self, project_path: Path, file_structure: Dict, heuristic_report: Dict = None) -> Dict:
        """Fallback static analysis if Gemini fails, enhanced by Heuristic Engine"""
        
        # Start with heuristic report as base if available
        base_framework = 'unknown'
        base_confidence = 0
        if heuristic_report:
            base_framework = heuristic_report.get('framework', 'unknown')
            base_confidence = heuristic_report.get('confidence', 0)
        
        analysis = {
            'language': 'unknown',
            'framework': base_framework,
            'entry_point': None,
            'port': self._detect_port(project_path, file_structure),
            'health_check_path': '/',
            'health_check_type': 'http',
            'memory_limit': '512Mi',
            'cpu_limit': '1',
            'dependencies': [],
            'database': None,
            'build_tool': None,
            'build_output': heuristic_report.get('build_output', 'dist') if heuristic_report else 'dist',
            'start_command': None,
            'env_vars': [],
            'runtime_version': heuristic_report.get('runtime_version', 'unknown') if heuristic_report else 'unknown',
            'dockerfile_exists': False,
            'recommendations': ['Unable to fully analyze project - using heuristic detection'],
            'warnings': ['Automated AI analysis failed - fallback to heuristics']
        }
        
        # Basic detection logic
        if 'package.json' in file_structure['config_files']:
            analysis['language'] = 'nodejs'
            analysis['build_tool'] = 'npm'
            try:
                pkg = json.loads((project_path / 'package.json').read_text())
                deps = pkg.get('dependencies', {})
                dev_deps = pkg.get('devDependencies', {})
                scripts = pkg.get('scripts', {})
                
                # ‚úÖ CRITICAL: Smart build_output detection
                # CRA (react-scripts) outputs to 'build/', Vite outputs to 'dist/'
                build_script = scripts.get('build', '')
                if 'react-scripts' in build_script or 'react-scripts' in str(deps):
                    analysis['build_output'] = 'build'
                    analysis['framework'] = 'react'  # Mark as CRA
                    print(f"[CodeAnalyzer] ‚úÖ Detected react-scripts, build_output='build'")
                elif 'vite' in build_script or 'vite' in str(dev_deps) or 'vite' in str(deps):
                    analysis['build_output'] = 'dist'
                    analysis['framework'] = 'vite'
                    print(f"[CodeAnalyzer] ‚úÖ Detected Vite, build_output='dist'")
                elif 'next' in deps:
                    analysis['build_output'] = '.next'
                    analysis['framework'] = 'nextjs'
                    print(f"[CodeAnalyzer] ‚úÖ Detected Next.js, build_output='.next'")
                
                # Framework fallback detection
                if '@nestjs/core' in deps or '@nestjs/common' in deps:
                    analysis['framework'] = 'nestjs'
                    analysis['build_output'] = 'dist'
                    print(f"[CodeAnalyzer] ‚úÖ Detected NestJS, build_output='dist'")
                elif 'next' in deps:
                    analysis['framework'] = 'nextjs'
                    analysis['build_output'] = '.next'
                elif 'express' in deps:
                    analysis['framework'] = 'express'
                elif 'fastify' in deps:
                    analysis['framework'] = 'fastify'
                elif 'vite' in deps or 'vite' in dev_deps:
                    analysis['framework'] = 'vite'
                    analysis['build_output'] = 'dist'
                elif 'react-scripts' in deps or 'react-scripts' in dev_deps:
                    analysis['framework'] = 'cra'
                    analysis['build_output'] = 'build'
                elif analysis['framework'] == 'unknown':
                    # [FAANG] If we didn't detect CRA/Vite above but have react, use react as framework
                    if 'react' in deps or 'react-dom' in deps:
                        analysis['framework'] = 'react'
                        analysis['build_output'] = 'dist'
            except Exception as e:
                print(f"[CodeAnalyzer] Warning: Could not parse package.json: {e}")
        
        elif 'requirements.txt' in file_structure['config_files']:
            analysis['language'] = 'python'
            analysis['build_tool'] = 'pip'
            
            # Check for Flask/Django/FastAPI
            for py_file in ['app.py', 'main.py', 'manage.py']:
                if py_file in file_structure['files']:
                    analysis['entry_point'] = py_file
                    break
        
        elif 'go.mod' in file_structure['config_files']:
            analysis['language'] = 'golang'
            analysis['build_tool'] = 'go'
            analysis['entry_point'] = 'main.go'
        
        analysis['env_vars'] = self._extract_env_vars(project_path)
        analysis['dockerfile_exists'] = (project_path / 'Dockerfile').exists()
        
        # [FAANG] Port sensing
        analysis['port'] = self._detect_port(project_path, file_structure)
        
        return analysis

    def _detect_port(self, project_path: Path, file_structure: Dict) -> dict:
        """
        FAANG-Level Port Sensing Logic with Dual Port Detection
        Returns both dev_port (local development) and deploy_port (Cloud Run production)
        
        Priority:
        1. Check .env files for PORT
        2. Scan package.json scripts
        3. Simple regex scan of entry files
        4. Framework defaults (dev vs deploy)
        """
        dev_port = None
        deploy_port = 8080  # Cloud Run standard
        
        # 1. Environment Overrides (Highest priority as they usually mean developer intention)
        env_files = ['.env', '.env.local', '.env.example']
        for env_file in env_files:
            env_path = project_path / env_file
            if env_path.exists():
                try:
                    content = env_path.read_text()
                    match = re.search(r'^PORT\s*=\s*(\d+)', content, re.MULTILINE)
                    if match:
                        p = int(match.group(1))
                        print(f"[CodeAnalyzer] Detected PORT from {env_file}: {p}")
                        dev_port = p
                        break
                except: pass

        # 2. Package.json scripts (e.g. "start": "next start -p 3000")
        if 'package.json' in file_structure['config_files']:
            try:
                pkg = json.loads((project_path / 'package.json').read_text())
                scripts = pkg.get('scripts', {}).values()
                for script in scripts:
                    match = re.search(r'--port\s+(\d+)|-p\s+(\d+)', script)
                    if match:
                        p = int(match.group(1) or match.group(2))
                        print(f"[CodeAnalyzer] Detected PORT from scripts: {p}")
                        if not dev_port:
                            dev_port = p
                        break
                
                # Dependencies-based defaults for dev_port
                deps = pkg.get('dependencies', {})
                dev_deps = pkg.get('devDependencies', {})
                
                if not dev_port:
                    # [FAANG] Vite uses 5173 by default for development
                    if 'vite' in deps or 'vite' in dev_deps:
                        dev_port = 5173
                        print(f"[CodeAnalyzer] Vite detected - dev_port: 5173, deploy_port: 8080")
                    elif 'next' in deps:
                        dev_port = 3000
                    elif '@nestjs/core' in deps:
                        dev_port = 3000
                    elif 'express' in deps:
                        dev_port = 3000
                    elif 'fastify' in deps:
                        dev_port = 3000
            except: pass

        # 3. Python Hardcodes (Top level)
        for py_file in ['main.py', 'app.py', 'manage.py']:
            if py_file in file_structure['files']:
                try:
                    content = (project_path / py_file).read_text()
                    # Check for uvicorn/flask port=...
                    match = re.search(r'port\s*=\s*(\d+)', content)
                    if match:
                        p = int(match.group(1))
                        print(f"[CodeAnalyzer] Detected PORT in {py_file}: {p}")
                        if not dev_port:
                            dev_port = p
                        break
                except: pass

        # 4. Default fallback
        if not dev_port:
            dev_port = deploy_port
        
        return {
            'dev_port': dev_port,
            'deploy_port': deploy_port
        }

    def summarize_project(self, project_path: str) -> str:
        """Create a compressed semantic summary of the project for LLM context"""
        path = Path(project_path)
        if not path.exists():
            return "Project path not found."
            
        file_structure = self._scan_directory(path)
        
        # Select key files to show content
        important_file_contents = []
        key_files = ['package.json', 'requirements.txt', 'Dockerfile', 'app.py', 'main.py', 'index.js']
        
        for f in file_structure['config_files']:
            if any(key in f for key in key_files):
                try:
                    content = (path / f).read_text()
                    # Limit to 1000 chars per file to save tokens
                    summary_content = content[:1000] + ("..." if len(content) > 1000 else "")
                    important_file_contents.append(f"--- {f} ---\n{summary_content}")
                except:
                    continue
        
        summary = f"""
PROJECT STRUCTURE:
- Files: {len(file_structure['files'])}

FILE TREE (Top 20):
{chr(10).join(file_structure['files'][:20])}

KEY FILE CONTENTS:
{chr(10).join(important_file_contents)}
""".strip()
        return summary


# Test analyzer
async def test_analyzer():
    import os
    from dotenv import load_dotenv
    import tempfile
    
    load_dotenv()
    
    gcloud_project = os.getenv('GOOGLE_CLOUD_PROJECT')
    analyzer = CodeAnalyzerAgent(gcloud_project=gcloud_project)
    
    # Create mock Flask project
    temp_dir = tempfile.mkdtemp()
    temp_path = Path(temp_dir)
    
    (temp_path / 'app.py').write_text("""
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello():
    return 'Hello World'

if __name__ == '__main__':
    app.run(port=5000)
""")
    
    (temp_path / 'requirements.txt').write_text("""
flask==3.0.0
psycopg2==2.9.9
gunicorn==21.2.0
""")
    
    (temp_path / '.env').write_text("""
DATABASE_URL=postgresql://localhost/mydb
SECRET_KEY=mysecret
""")
    
    print("üîç Analyzing project...\n")
    analysis = await analyzer.analyze_project(temp_dir)
    
    print(json.dumps(analysis, indent=2))
    
    # Cleanup
    import shutil
    shutil.rmtree(temp_dir)

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_analyzer())
